<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.jpeg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.jpeg?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.jpeg?v=5.1.4">


  <link rel="mask-icon" href="/images/favicon.jpeg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Zhiqi Liu">
<meta property="og:url" content="https://liuzhiqi.github.io/blog/index.html">
<meta property="og:site_name" content="Zhiqi Liu">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Zhiqi Liu">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://liuzhiqi.github.io/blog/">





  <title>Zhiqi Liu</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zhiqi Liu</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-articles">
          <a href="/articles" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br>
            
            Articles
          </a>
        </li>
      
        
        <li class="menu-item menu-item-notes">
          <a href="/categories/Notes" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-wpforms"></i> <br>
            
            Notes
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-notes" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liuzhiqi.github.io/blog/2020/11/12/【Paper-Reading】A-Survey-on-Network-Embedding/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiqi Liu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiqi Liu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2020/11/12/【Paper-Reading】A-Survey-on-Network-Embedding/" itemprop="url">【Paper Reading】A Survey on Network Embedding</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-11-12T22:13:11+08:00">
                2020-11-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<h1 id="【Paper-Reading】A-Survey-on-Network-Embedding"><a href="#【Paper-Reading】A-Survey-on-Network-Embedding" class="headerlink" title="【Paper Reading】A Survey on Network Embedding"></a>【Paper Reading】A Survey on Network Embedding</h1><h2 id="2-分类与方法"><a href="#2-分类与方法" class="headerlink" title="2 分类与方法"></a>2 分类与方法</h2><h3 id="2-1-分类"><a href="#2-1-分类" class="headerlink" title="2.1 分类"></a>2.1 分类</h3><h4 id="2-1-2-只考虑拓扑信息的网络"><a href="#2-1-2-只考虑拓扑信息的网络" class="headerlink" title="2.1.2 只考虑拓扑信息的网络"></a>2.1.2 只考虑拓扑信息的网络</h4><ol>
<li>只考虑网络拓扑结构，相关的工作尝试保留网络的结构信息：如节点和边、邻居结构、高阶节点邻近度、社区结构等。<br>  from nodes and links [10] to neighborhood structure [3], high-order proximities of nodes [6], and community structures [4].</li>
<li>考虑网络结构属性，（如三角闭合性、结构平衡性质）<br> To name a few, network transitivity (i.e. triangle closure) is the driving force of link formation in networks [11], and structural balance property plays an important role in the evolution of signed networks [12].</li>
<li>考虑原始网络空间和embedding空间的统一性<br>  Some recent studies begin to look into this problem<br>and demonstrate the possibility of aligning these two spaces at the property level [8], [13].</li>
</ol>
<h4 id="2-1-3-带侧信息的NE"><a href="#2-1-3-带侧信息的NE" class="headerlink" title="2.1.3 带侧信息的NE"></a>2.1.3 带侧信息的NE</h4><p>除了网络的拓扑之外，一些网络还伴随着丰富的附加信息，如：节点内容和标签node content or labels in information networks [14]、节点和边的属性node and edge attributes in social networks [15]、异构网络中节点的类型node types in heteroge- neous networks [16]。<br>主要的挑战在于如何结合并平衡拓扑和附加信息在NE中的作用。Some multimodal and multisource fusion techniques are explored in this line of research [15], [17].</p>
<h4 id="2-1-4-有监督方法"><a href="#2-1-4-有监督方法" class="headerlink" title="2.1.4 有监督方法"></a>2.1.4 有监督方法</h4><p>之前两类方法学习网络表示通常使用无监督的方式，学得的embedding是通用的，可用于各种任务。而针对不同的目标问题可以进一步优化，通常采用有监督的方式。<br>Directly designing a framework of representation learning for a particular target scenario is also known as an end-to-end solution [18]<br>Some recent works demonstrate the feasibility in applications such as cascading prediction [18], anomaly detection [21], network alignment [22] and collaboration prediction [23].</p>
<h3 id="2-2-常用方法"><a href="#2-2-常用方法" class="headerlink" title="2.2 常用方法"></a>2.2 常用方法</h3><h4 id="2-2-1-矩阵分解"><a href="#2-2-1-矩阵分解" class="headerlink" title="2.2.1 矩阵分解"></a>2.2.1 矩阵分解</h4><p>NE的目标是得到低维向量空间以表示网络，这与矩阵分解方法具有相同的目标。常用的矩阵分解模型：奇异值分解（SVD）、非负矩阵分解</p>
<h4 id="2-2-2-随机游走"><a href="#2-2-2-随机游走" class="headerlink" title="2.2.2 随机游走"></a>2.2.2 随机游走</h4><p>类比于Word2Vec，基于随机游走的模型在网络中进行随机游走。将节点作为语言模型中的词，将随机游走作为句子，节点邻居可以用Word2Vec中共同出现的概率来定义。代表工作：DeepWalk（KDD 2014），Node2Vec（KDD 2016）</p>
<h4 id="2-2-3-深度神经网络"><a href="#2-2-3-深度神经网络" class="headerlink" title="2.2.3 深度神经网络"></a>2.2.3 深度神经网络</h4><p>作为非线性的学习模型，深度神经网络取得了很大的成功。代表性的使用深度神经网络的NE方法： SDNE [6], SDAE [26], and SiNE [13],</p>
<h2 id="3-Network-Embedding和Graph-Embedding对比"><a href="#3-Network-Embedding和Graph-Embedding对比" class="headerlink" title="3 Network Embedding和Graph Embedding对比"></a>3 Network Embedding和Graph Embedding对比</h2><p>Graph embedding（GE）的目标与network embedding的目标相似，是将一个图（graph）嵌入到低维的向量空间。传统的图嵌入方法，图是从以特征表示的数据集中构造得到的，如图像数据集。GE综述（Fu and Ma 2012）</p>
<h3 id="3-1-代表性的GE方法"><a href="#3-1-代表性的GE方法" class="headerlink" title="3.1 代表性的GE方法"></a>3.1 代表性的GE方法</h3><p>GE方法起初是作为一种降维的技术来被学习的。 一个图通常是由一些有特征的数据集构成的，如图像数据集。<br>作者主要提到了三种方法，Isomap，LLE，LE。均为经典流行学习的方法。这些方法均利用特征构建出图结构，并利用图结构行计算。</p>
<h4 id="Isomap-28-："><a href="#Isomap-28-：" class="headerlink" title="Isomap[28]："></a>Isomap[28]：</h4><p>Isomap 为经典流行学习方法，假设高维的数据都存在低维的本征结构。<br>Isomap利用流形在局部上与欧氏空间同胚这个性质（一个点的小邻域内，在流形空间的距离与实际空间中的距离近似），对每个点基于欧氏距离找出其近邻点，然后就能建立一个近邻连接图，图中近邻点之间存在连接，而非近邻点之间不存在连接，于是，计算两点之间测地线距离的问题就转变为计算近邻连接图上两点之间的最短路径问题.<br>Isomap通过使用连接线算法（如：knn）构建了一个邻居网络，从而构成流行空间，在近邻连接图上计算两点间的最短路径，从而构建距离矩阵。最终利用MDS的方法得到流行空间的表示(优化如下目标)。   </p>
<script type="math/tex; mode=display">
J(x') = \sum _i ^ N {|| (||x' _i - x' _j|| - d _{ij}} )|| \\\\</script><h4 id="LLE-局部线性嵌入"><a href="#LLE-局部线性嵌入" class="headerlink" title="LLE 局部线性嵌入."></a>LLE 局部线性嵌入.</h4><p>LLE同样使用连接线算法（如：knn）构建了一个邻居网络。Isomap构建网络目的是为了得到距离矩阵，而LLE构建网络则是希望能保证点与其紧邻的关系在变幻前后保持不变。<br>当构建好邻居网络之后，使用邻居节点来对自身点进行线性表示（ \( x _i = \sum _k ^K \omega _ {ij} x _j  \) ）。我们希望在进行流形变换之后的流形空间里，临近点同样保持相应的关系（ \( x’ _i = \sum _k ^K \omega _{ij} x’ _j  \), x’为变换后的x）。这一步，我们使用均方误差作为回归问题损失函数。  </p>
<script type="math/tex; mode=display">
\begin{cases}
J(\omega) = \sum _i ^ N {||x' _i - \sum _{x' _j \in G(x' _i)} \omega _{ij} x' _j || _2 ^2}  \\\\
\sum _{x _j \in G(x _i)} \omega _{ij} =1
\end{cases}</script><p>利用拉格朗日子乘法来求解这个最优化问题。<br>得到原始空间权重之后。我们反过来求解流形空间的点的表示。同样使用均方误差作为回归问题损失函数。       </p>
<script type="math/tex; mode=display">
J(x') = \sum _i ^ N {||x' _i - \sum _{x' _j \in G(x' _i)} \omega _{ij} x' _j || _2 ^2}  \\\\</script><h4 id="Laplacian-Eigenmaps-拉普拉斯特征映射"><a href="#Laplacian-Eigenmaps-拉普拉斯特征映射" class="headerlink" title="Laplacian Eigenmaps 拉普拉斯特征映射"></a>Laplacian Eigenmaps 拉普拉斯特征映射</h4><p>LE方法同样需要构建邻居网络，LE的目标是保证小邻域间的点的距离尽可能保持较小的状态。LE构建好邻居网络之后，利用邻居网络构建邻接矩阵：   </p>
<script type="math/tex; mode=display">
W_{ij} = e ^{-\frac{||x _i-x _j|| _2}{t}}</script><p>或直接利用邻接矩阵连通性：   </p>
<script type="math/tex; mode=display">
W _{ij} = \begin{cases}
1 \ if\ i\ and\ j\ is\ connected\\\\
0\ other
\end{cases}</script><p>通过优化，得到输出空间。</p>
<script type="math/tex; mode=display">
min\ arg _{x'} \sum _i \sum _j {||x' _i -x' _j|| ^2}W _{ij} =min\ arg _{X'} trace(X' ^TLX') \\\\
L = D-W \\\\
D _{ii} = \sum _{j=1} ^n W _{ij}</script><h3 id="3-2-Network-Embedding和Graph-Embedding区别"><a href="#3-2-Network-Embedding和Graph-Embedding区别" class="headerlink" title="3.2 Network Embedding和Graph Embedding区别"></a>3.2 Network Embedding和Graph Embedding区别</h3><p>区别主要存在于两个方面：目标与假设。<br>目标：<br>Network Embedding的目标在于：重建原始网络+网络推断。<br>Graph embedding主要目标是网络的重建。<br>因此，graph embedding 可以视为一种特殊的Network embedding，只考虑重建网络的network embedding。<br>GE更多的是处理数据特征特征的图结构，在原始特征空间中，图的权重可以被很好定义。而NE大多是处理真实的网络结构，例如社交网络，金融网络等。在这样的网络里，边之间的权重不好定义，可能需要特殊的分析与处理或特殊场景。<br>而现在的研究更注重网络的inference，因此NE也是本文接下来的重点。</p>
<h2 id="4-STRUCTURE-AND-PROPERTY-PRESERVING-NETWORK-EMBEDDING"><a href="#4-STRUCTURE-AND-PROPERTY-PRESERVING-NETWORK-EMBEDDING" class="headerlink" title="4 STRUCTURE AND PROPERTY PRESERVING NETWORK EMBEDDING"></a>4 STRUCTURE AND PROPERTY PRESERVING NETWORK EMBEDDING</h2><p>对于NE，最主要的目标就是保留网络结构和捕获网络特征。通常网络结构包括一阶网络特征和高阶网络特征。</p>
<h3 id="4-1-Structure-Preserving-Network-Embedding"><a href="#4-1-Structure-Preserving-Network-Embedding" class="headerlink" title="4.1 Structure Preserving Network Embedding"></a>4.1 Structure Preserving Network Embedding</h3><p>网络结构根据不同的力度可以分为不同类型。在NE方法中一般来说挖掘网络结构主要包括，邻居结构，高阶节点邻接特性和网络社群发现。   </p>
<h4 id="DeepWalk-3"><a href="#DeepWalk-3" class="headerlink" title="DeepWalk[3]"></a>DeepWalk[3]</h4><p>是早期影响力较大的图结构embedding方法。它主要是通过在图结构上随机游走，并将游走路径中节点生成序列。在随机游走过程中，利用权重生成转移概率：</p>
<script type="math/tex; mode=display">
P(v _j | v _i) =  \begin{cases}
\frac {M _ij}{\sum _{j \in {N _+(v _i)}} M _{ij}} v _ \in N _{+}(V _i)  \\\\
0\ e _{ij }\notin \epsilon
\end{cases}</script><p>其中M矩阵为权重矩阵，若无权重也可设为1.</p>
<h4 id="Node2vec-25"><a href="#Node2vec-25" class="headerlink" title="Node2vec[25]"></a>Node2vec[25]</h4><p>在DeepWalk基础上更进一步，他通过调整随机游走的权重的方法，使Embedding的结果可以倾向于同质性（距离相近的节点更相似）或结构性（结构相似的节点更加相似）。Node2vec 主要使用了权衡BFS 和DFS的方法，通过控制节点跳转概率达到调整的目的。其具体转移概率如下：  </p>
<script type="math/tex; mode=display">
\alpha _{pq}(t,x) = \begin{cases}
1/p ,if \ d _{tx} = 0（返回上一节点）\\\\
1 ,if \ d _{tx} = 1（保持1度关系）\\\\
1 ,if \ d _{tx} = 2（远离上一节点）
\end{cases}</script><script type="math/tex; mode=display">
P(x|v) = \alpha _{pq}(t,x)*\omega _{vx}</script><p>其中d 表示节点间距离，w表示权重，p为返回参数，p越小，随机游走回上一节点概率越大，q为进出参数，q越小，随机游走到远处概率越大。  </p>
<h4 id="LINE-10"><a href="#LINE-10" class="headerlink" title="LINE[10]"></a>LINE[10]</h4><p>可以应用于大规模网络中，其考虑网络的一阶和二阶相似性。一阶相似性是联合概率分布，由节点对之间的相似性来度量；二阶相似性是条件概率分布，通过节点生成其上下文节点的概率来度量；  </p>
<script type="math/tex; mode=display">
P1(v _i, v _2) = \frac {1}{1+exp(-u _i ^T u _j)}</script><script type="math/tex; mode=display">
P2(v _i | v _2) = \frac {exp(\overline u _j ^T \overline u _i)}{1+exp(-\overline u _i ^T \overline u _j)}</script><p>利用KL散度对最终结果进行优化（比较概率分布与边权重变化后得到的实际关系重要度）。得到一二阶特征后，可以通过特征拼接的方式组合简单组合在一起。  </p>
<h4 id="GraRep-【-Need-dive-deep-】："><a href="#GraRep-【-Need-dive-deep-】：" class="headerlink" title="GraRep 【## Need dive deep ##】："></a>GraRep 【## Need dive deep ##】：</h4><p>LINE只考虑一阶和二阶，GrapRep考虑K阶（K&gt;2）相似性。给定一个邻接矩阵A，k步概率转移矩阵可通过矩阵相乘计算得到。</p>
<h4 id="M-NMF"><a href="#M-NMF" class="headerlink" title="M-NMF:"></a>M-NMF:</h4><p>之前的NE主要从保留相近节点的关系来做Embedding。M-NMF则从社群划分的角度进行切入。<br>这里M-NMF优化目标可以分为两部分，矩阵相似度特征部分和社群部分。<br>矩阵相似度部分主要衡量了点和点的相似度。M-NMF主要使用了一阶相似度和二阶相似度。其中一阶相似度使用了邻接矩阵，作为相似度矩阵。二阶相似度矩阵则由两点的邻接向量的余弦距离定义。最终相似度矩阵由一阶二阶相似度矩阵加权拼接得到：\(  S = S ^{(1)} + \eta S ^{(2)}  \)    </p>
<p>社群部分主要使用了Q-Modularity来衡量社群划分水平（见：基础社群分析<br>）。通过优化：\( Tr(H ^TBH) \)来优化社群。<br>为了得到Embedding向量，M-NMF使用了矩阵分解，目标函数如下：</p>
<script type="math/tex; mode=display">
argmin(M,U,H,C)||S - MU ^T|| ^2 _F + \alpha||H - UC ^T|| ^2 _F -\beta Tr(H ^TBH)</script><p>其中U为节点表示矩阵，M为节点-节点偏好矩阵，C为社区特征矩阵。铜鼓轮流更新M、U、H、C来优化方程。</p>
<p>从公式中我们可以看到，作者通过引入一个新的“社区表达矩阵”C，结合“节点表达矩阵”U，通过矩阵分解的方法来结合模块度公式中原有的“社区矩阵”H，这样一来，embedding的过程中使用模块度公式来约束社区结构。但是这种方法引入的假设变量有点多，虽然实验效果不错，但解释起来始终有些牵强。同时，矩阵分解方法需要开的内存太高，难以针对大规模数据。</p>
<h4 id="SDNE"><a href="#SDNE" class="headerlink" title="SDNE"></a>SDNE</h4><p>SDNE可以看作是基于LINE的扩展，同时也是第一个将深度学习应用于网络表示学习中的方法。SDNE解决高非线性、结构保护和稀疏性问题，SDNE深度自编码器的基础上，优化了自编码器损失函数，同时对表示层也加入了有监督的损失函数。<br>传统自编码器损失函数：  </p>
<script type="math/tex; mode=display">
L = \sum _{i=1} ^n||\hat x _i - x _i|| _2 ^2</script><p>我们只能根据已有的连接表示节点之间的相似性,但对它们的差异无法作出比较好的衡量。<br>而且由于网络稀疏,输入实例中0元素的数目远多于非0元素。因此SDNE对损失函数加入了更多罚项：</p>
<script type="math/tex; mode=display">
L = \sum _{i=1} ^n||(\hat x _i - x _i)\cdot b _i|| _2 ^2</script><p>其中bi 由邻接矩阵得到，若i j对应到邻接矩阵等于0，则 \( b _{ij} = 1 \) 。否则\( b _{ij}=\beta &gt;1 \) 。通过自编码器,如果两个节点具有相近的邻接点结构,则在表示空间中距离越近（因为损失函数加入了更多邻接信息罚项）。<br>另一方面，对于表示层，SDNE加入了损失函数：  </p>
<script type="math/tex; mode=display">
L = \sum _{i,j=1} ^n s _{i,j} ||y _i ^{(K)}-y _j ^{(K)} ||</script><p>其中 \(  y _i ^{(K)} \)为自编码器得到的编码层，s为邻接矩阵。从而在表示层加入了一阶邻接信息。同时为了优化算法，在表示层的学习中加入了Laplacian Eigenmaps的思想，通过构建相似关系图来重构局部特征结构，从而使局部小临域内点更接近。</p>
<h4 id="Cao-2017"><a href="#Cao-2017" class="headerlink" title="Cao 2017"></a>Cao 2017</h4><p>对于Deep Walk模型而言，其长度有限，处于边缘的节点信息没有用全，且参数难调。因此Cao提出了一个深度学习的模型来学习图的顶点表示，借鉴了PageRank，结合加权转移概率矩阵，先用一个随机搜索模型来获取图的结构信息，生成一个共现概率矩阵，和DeepWalk相比是省去了一个采样的过程，然后基于共现概率矩阵计算PPMI矩阵，PPMI矩阵可以看成是稀疏的顶点高维表示，再用堆叠自动编码器从PPMI矩阵中学习到顶点的低维表示。</p>
<h4 id="GEM-D-2017"><a href="#GEM-D-2017" class="headerlink" title="GEM-D 2017"></a>GEM-D 2017</h4><p>提出一个NE框架，统一之前的算法。包括三个度量 [h(⋅),g(⋅),d(⋅,⋅)]。 分别为邻近度函数，非线性函数，度量h和g差异性的度量函数。</p>
<h3 id="4-2-Property-Preserving-Network-Embedding"><a href="#4-2-Property-Preserving-Network-Embedding" class="headerlink" title="4.2 Property Preserving Network Embedding"></a>4.2 Property Preserving Network Embedding</h3><p>上文提到的方法，大多focus在网络的结构或者节点间的关系身上，实际上除了结构之外，我们同样也关注节点或边自身的性质。</p>
<h4 id="Multi-Component-Hashing-Ou-et-al-2015-44"><a href="#Multi-Component-Hashing-Ou-et-al-2015-44" class="headerlink" title="Multi-Component Hashing [Ou et al 2015.[44]]"></a>Multi-Component Hashing [Ou et al 2015.[44]]</h4><p>MuCH的核心是解决网络结构中关系非传递性问题（A与B存在关系，B与C存在关系，A与C不存在关系）。<br>MuCH使用了投影矩阵，通过构建M个投影矩阵\( \{W _i\} ^M \)，将每个个体重新用M个Hash向量表示，在进行目标优化时，使用了实体间真实相似性。这样做的好处是一方面使用投影矩阵压缩了特征表示，同时，也使表示能反应真实的相似性，最后得到的哈希表示，也使目标查询更加方便与快速。（PS：感觉似乎就是一个简单的神经网络，使用一层分M块参数矩阵 \( \{W _i\} ^M \)，激活函数使用sgn，输出使用softmax）</p>
<h4 id="Max-Margin-DeepWalk-Asymmetric-Transitivity-Preserving-Graph-Embedding-HOPE-2016-8"><a href="#Max-Margin-DeepWalk-Asymmetric-Transitivity-Preserving-Graph-Embedding-HOPE-2016-8" class="headerlink" title="Max-Margin DeepWalk: Asymmetric Transitivity Preserving Graph Embedding [HOPE 2016 [8]]"></a>Max-Margin DeepWalk: Asymmetric Transitivity Preserving Graph Embedding [HOPE 2016 [8]]</h4><p>考虑有向网络的非对称传递性（A-&gt;B B-&gt;C 则有 A-&gt;C （而不是C-&gt;A））。对于每个顶点，该方法的到两个embedding后的向量，一个是source，一个是target。因为是有向图，此顶点可能是一条路径的源头，也有可能是一条路径的终点。方法的目标是优化：</p>
<script type="math/tex; mode=display">
min||S - U ^s {U ^t} ^T|| _F ^2</script><p>其中S为相似矩阵，因为是有向图，所以其\( S _{ij} \)表示节点i作为source顶点与节点j作为target顶点的相似度。两个不同的U矩阵分别代表顶点作为source和target的Embedding向量矩阵。</p>
<p>该方法实际上是希望找到节点作为source和targe的不同embedding表示，同时该表示能还原节点的相似度。即希望：</p>
<script type="math/tex; mode=display">
S = \sum _{i} ^N \sigma _i v _i ^s {v _i ^t} ^T \\\\
U ^s = [\sqrt{\sigma _1}v _1 ^s,\dots,{\sigma _K}v _K ^s] \\\\
U ^t = [\sqrt{\sigma _1}v _1 ^t,\dots,{\sigma _K}v _K ^t] \\\\
S = V ^s \Sigma V ^t</script><p>即希望S可通过SVD得到U。</p>
<p>为了度量S相似性矩阵，HOPE总结了4种度量方法：Katz Index [45], Rooted PageRank [7], Common Neighbors [7], and Adamic-Adar [46]，相关内容可见《<a href>网络节点距离度量</a>》。  </p>
<p>由于先求S在对S进行SVD对大数据不太友好，因此作者使用了以下方法：</p>
<h5 id="Katz-Index"><a href="#Katz-Index" class="headerlink" title="Katz Index"></a>Katz Index</h5><script type="math/tex; mode=display">
M _g = (I -\beta A)   \\\\
M _l =   \beta A</script><h5 id="Rooted-PageRank-RPR"><a href="#Rooted-PageRank-RPR" class="headerlink" title="Rooted PageRank (RPR)"></a>Rooted PageRank (RPR)</h5><script type="math/tex; mode=display">
M _g = (1-\alpha P)   \\\\
M _l =   (1-\alpha) I</script><h5 id="Rooted-PageRank-RPR-1"><a href="#Rooted-PageRank-RPR-1" class="headerlink" title="Rooted PageRank (RPR)"></a>Rooted PageRank (RPR)</h5><script type="math/tex; mode=display">
M _g = I  \\\\
M _l = A ^2</script><h5 id="Adamic-Adar-AA）"><a href="#Adamic-Adar-AA）" class="headerlink" title="Adamic-Adar (AA）"></a>Adamic-Adar (AA）</h5><script type="math/tex; mode=display">
M _g = I  \\\\
M _l = ADA</script><p>因此s的svd变成了：</p>
<script type="math/tex; mode=display">
M _g ^{-1}M _l = V ^s \Sigma{V ^t} ^T \\\\
 = ADA</script><p>将原始SVD转变为通用的SVD问题，也就是可以不求s直接进行SVD。</p>
<h4 id="SiNE（2017）"><a href="#SiNE（2017）" class="headerlink" title="SiNE（2017）"></a>SiNE（2017）</h4><hr>
<p><a href="https://blog.csdn.net/travalscx/article/details/86670523" target="_blank" rel="noopener">论文笔记：Asymmetric Transitivity Preserving Graph Embedding</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-notes" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liuzhiqi.github.io/blog/2020/06/17/社交网络距节点离度量方法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiqi Liu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiqi Liu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2020/06/17/社交网络距节点离度量方法/" itemprop="url">社交网络距节点离度量方法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-06-17T00:21:12+08:00">
                2020-06-17
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<h1 id="社交网络距节点离度量方法"><a href="#社交网络距节点离度量方法" class="headerlink" title="社交网络距节点离度量方法"></a>社交网络距节点离度量方法</h1><h2 id="Path-based-Methods"><a href="#Path-based-Methods" class="headerlink" title="Path-based Methods"></a>Path-based Methods</h2><h3 id="Graph-Distance"><a href="#Graph-Distance" class="headerlink" title="Graph Distance"></a>Graph Distance</h3><p>直接度量两个节点间距离，例如使用Dijkstra。但对于大规模网络而言Dijkstra算法较为时间复杂度太高。<br>可以引入六度关系理论（Small-World Phenomenon），比如说要计算x，y两点距离，我们先初始化两个集合 S={x}、D={y}。然后开始扩展S和D的集合，扩展的方法就是不断地把集合里面元素的邻居放进去，比如一开始就是把x的邻居放进集合S中，y的邻居放进D中。放入时，除了邻居节点，还应加入当放入节点距起始节点距离（邻居节点距起始节点距离+1），重复放入时，节点距离取最小的距离。一直循环，直到S和D出现相同的元素为止，此时xy的距离为各自到相同元素的距离之和。<br>根据small world phenomenon来说，扩展的次数不会太多。另外效率起见，我们一般选择元素数量较少的那个来扩展。</p>
<h3 id="Hitting-Time"><a href="#Hitting-Time" class="headerlink" title="Hitting Time"></a>Hitting Time</h3><p>为了加快计算速度，可以使用蒙特卡洛的技术来估计x，y的路径的数量。从x出发，在附近随机的跳转，如果到达y，则记录下这次到达y的所需跳转次数。最后我们用总跳转次数除以到达y的次数来表示距离。</p>
<h3 id="Rooted-PageRank"><a href="#Rooted-PageRank" class="headerlink" title="Rooted PageRank"></a>Rooted PageRank</h3><p>然而，如果y是一个非常有影响力的人，那么很多人都能在非常少的跳转次数下到达y，为了减轻这效应，我们增加一个随机”reset”以及继续游走的机制。当到达y时，以概率α继续向邻居跳转，以1−α返回上一节点。根据pageRank的理论，当转移矩阵趋于平稳时，有：</p>
<script type="math/tex; mode=display">
S = \alpha SP+(1-\alpha)I\\\\
\sum _{ij} P  _{ij}   = 1</script><p>其中P为转移概率矩阵，元素均大于0，可通过归一化A得到。等式整理可得：</p>
<script type="math/tex; mode=display">
S=(1-\alpha)\cdot (1-\alpha P) ^ {-1}</script><p>该方法的时间复杂度为\(O(v ^{3})\) （v为点数）。因为实际过程为迭代过程，为了加快计算，我们采用Rooted PageRank的蒙特卡洛方法来近似计算相似度矩阵。基本思想：以c为停止概率，从点v出发独立随机采样N条路径，那么u相对于v的相似度就可以认为是能到达u的路径占N条路径的比。</p>
<h3 id="Katz-指标（Katz-Index-KI）"><a href="#Katz-指标（Katz-Index-KI）" class="headerlink" title="Katz 指标（Katz Index,KI）"></a>Katz 指标（Katz Index,KI）</h3><p>Katz 指标可以区分不同的邻居节点不同的影响力。Katz 指标给邻居节点赋予不同的权重, 对于短路径赋予较大的权重, 而长路径赋予较小的权重。</p>
<p>两个节点之间的相似度定义为：</p>
<script type="math/tex; mode=display">
s(x,y) = \sum _l ^ \infty \beta ^l |Paths _{xy} ^l|=\sum _l ^ \infty \beta ^l (A ^l) _{xy}</script><p>其中Paths表示从x到y长度为l的路径数量，A为邻接矩阵，A的l次幂每一项相当于从x到y路径长度为l的个数。\(\beta\)为权重衰减因子，衡量重要度时，l越大，l阶对最终相似度的影响应该越小。为保证数列收敛，\(\beta\)应小于邻接矩阵A的最大特征值的倒数。<br>从上式我们可以推到出其矩阵表示：</p>
<script type="math/tex; mode=display">
S = \beta A + \beta ^2 A ^2 + \dots = (I -\beta A) ^{-1} - I</script><p>推导过程：</p>
<script type="math/tex; mode=display">
\beta AS = S - \beta A\\\\
(I -\beta A)(I + S) =I+S-\beta A -\beta AS =I</script><p>所以：</p>
<script type="math/tex; mode=display">
(I -\beta A) ^{-1} = (I + S)\\\\
S  = (I -\beta A) ^{-1} - I \\\\
S =  (I -\beta A) ^{-1} \cdot \beta A</script><p>Katz 指标的时间复杂度为\(O(vk+v ^{3}+v)\)，矩阵的减法和乘法是\(O(vk)\)，矩阵的逆运算是\(O(v ^{3})\)，减法是\(O(v)\)。故该方法的时间复杂度为\(O(v ^{3})\)。该方法的权重衰减因子的最优值只能通过大量的实验验证获得, 因此具有一定的局限性。</p>
<h2 id="Neighbor-based-Methods"><a href="#Neighbor-based-Methods" class="headerlink" title="Neighbor-based Methods"></a>Neighbor-based Methods</h2><h3 id="Common-Neighbors"><a href="#Common-Neighbors" class="headerlink" title="Common Neighbors"></a>Common Neighbors</h3><p>当两个用户有着很多个相同的邻居，我们就认为这两个用户很有可能建立联系。所以两个用户的相似性就用他们相同邻居的数量表示：</p>
<script type="math/tex; mode=display">
Score(x,y)=|\tau(x) \cap \tau(y)|</script><p>对于邻接矩阵A来说，有相似度矩阵：</p>
<script type="math/tex; mode=display">
S=A ^2</script><h3 id="Jaccard’s-Coefficient"><a href="#Jaccard’s-Coefficient" class="headerlink" title="Jaccard’s Coefficient"></a>Jaccard’s Coefficient</h3><p>然而Common Neighbors有一个很大的问题，假设有一个人有非常多的邻居，那么所有人都会倾向于预测跟他产生互动，为此，我们还要把他们邻居的数量考虑进去，于是我们认为，如果两个人共同邻居的数量在他们所有好友数量中占比越大，就认为可能建立联系。即</p>
<script type="math/tex; mode=display">
Score(x,y)= \frac {|\tau(x) \cap \tau(y)|}{|\tau(x) \cup \tau(y)|}</script><h3 id="Adamic-Adar-Frequency-Weighted-Common-Neighbors"><a href="#Adamic-Adar-Frequency-Weighted-Common-Neighbors" class="headerlink" title="Adamic/Adar (Frequency-Weighted Common Neighbors)"></a>Adamic/Adar (Frequency-Weighted Common Neighbors)</h3><p>这个方法同样是对Common Neighbors的改进，当我们计算两个相同邻居的数量的时候，其实每个邻居的“重要程度”都是不一样的，我们认为这个邻居的邻居数量越少，就越凸显它作为“中间人”的重要性，毕竟一共只认识那么少人，却恰好是x，y的好朋友，因此引入邻居的权重：</p>
<script type="math/tex; mode=display">
Score(x,y)=\sum _{z \in \tau(x) \cap \tau(y) } \frac 1 {\log|\tau (z)|}</script><p>这里权重引入了log衰减，也可以直接用和来表示权重。<br>若定义邻接矩阵为A，则我们可以引出矩阵表示：</p>
<script type="math/tex; mode=display">
S=ADA</script><p>其中D为：</p>
<script type="math/tex; mode=display">
D _{ii}=\frac 1 {\log\sum {(A _{ij}+A _{ji}})}</script><h3 id="Friendes-mearsure"><a href="#Friendes-mearsure" class="headerlink" title="Friendes-mearsure"></a>Friendes-mearsure</h3><p>既然两个人有相同的好友可以表达他们间的距离，那么我们可以把这一个思想推广，我们认为，他们的好友之间很有可能互为好友。我们就计算他们好友之间互为好友的数量作为评价标准。</p>
<script type="math/tex; mode=display">
Score(x,y)=\sum _{u \in \tau(x) } \sum _{v \in \tau(y) } \delta(x,y) \\\\
\delta(x,y) =  \begin{cases}
1 \ if\ u=v\ or\ A _{uv}=1\ or\ A _{uv}=1\\\\
0\ other
\end{cases}</script><h3 id="Preferential-Attachment"><a href="#Preferential-Attachment" class="headerlink" title="Preferential Attachment"></a>Preferential Attachment</h3><p>另外，如果两个用户拥有的好友数量越多，那么就越有可能更愿意去建立联系。也就是“富人越富”原则，基于这思想,用他们两个用户的好友数量的乘积作为评分。</p>
<script type="math/tex; mode=display">
Score(x,y)=|\tau(x)||\tau(y)|</script><hr>
<p><a href="https://blog.csdn.net/a358463121/article/details/79350292" target="_blank" rel="noopener">https://blog.csdn.net/a358463121/article/details/79350292</a></p>
<p><a href="https://blog.csdn.net/chuhang123/article/details/103289413" target="_blank" rel="noopener">https://blog.csdn.net/chuhang123/article/details/103289413</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-notes" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liuzhiqi.github.io/blog/2020/05/12/基础社群分析方法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiqi Liu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiqi Liu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2020/05/12/基础社群分析方法/" itemprop="url">基础社群分析方法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-05-12T22:13:11+08:00">
                2020-05-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<h1 id="基础社群分析方法"><a href="#基础社群分析方法" class="headerlink" title="基础社群分析方法"></a>基础社群分析方法</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>社区划分的算法比较多，大致可以分为两大类：    </p>
<ul>
<li>拓扑分析：前者一般适用于无向无权网络，思路是社区内部的连边密度要高于社区间。  </li>
<li>流分析：后者适用于有向有权网络，思路是发现在网络的某种流动（物质、能量、信息）中形成的社区结构。  
　</li>
</ul>
<h2 id="拓扑分析"><a href="#拓扑分析" class="headerlink" title="拓扑分析"></a>拓扑分析</h2><h3 id="计算网络的模块化程度Q-Modularity"><a href="#计算网络的模块化程度Q-Modularity" class="headerlink" title="计算网络的模块化程度Q-Modularity"></a>计算网络的模块化程度Q-Modularity</h3><p>Q-Modularity是一种定义社群划分的指标，其定义在[-0.5,1)区间。其具体计算公式如下：</p>
<script type="math/tex; mode=display">
Q = \sum _{ij} (A _{ij} - \frac {k _i} {2m} * \frac {k _j} {2m} ) \delta(c _i,c _j)</script><p>其中A为网络G的邻接矩阵，\( A <em>{ij} \) 为1表示从i到j存在边，反之为0。m表示总边数，2m则为每一个节点的度数和。\( \frac {A </em>{ij}} {2m}\) 为ij实际的链接概率。\( \frac {k <em>{i}k </em>{j}} {2m*2m}\) 表示保持i和j的度数，对网络的边进行随机分配，ij两点存在边的概率。\( \delta(c <em>i,c _j)\)表示i和j是否处于同一社群，是为1，否为0。<br>可见Q值越大说明当前社群划分，社群内部连边越多，也就是社群更加聚集。因此Q可以用来作为衡量社群划分好坏的一种度量。<br>Newman(2006)对上式进行了化简，定义\( S </em>{ir}\)为\(N \times R\)的矩阵，N是节点数，R是社区数。如果节点i属于社区r，则为1，否则为0，得到矩阵表达如下：</p>
<script type="math/tex; mode=display">
Q = \frac {1}{2m}\sum _{ij}\sum _r[A _{ij} - \frac {k _ik _j}{2m}]S _{ir}S _{jr}=\frac{1}{2m}Tr(S ^TBS)\\\\
B _{ij} = A _{ij} -  \frac{k _i k _j}{2m}</script><p>其中B行列和均为1。<br>通过一系列数值优化方法（Fast Greedy、Muti LevelGraRep <font color="#dd0000">【Need dive deep】</font>：）最大化Q，我们可以找到一个对网络的社群的划分。可以利用的方法有fast greedy和multi level等。</p>
<h4 id="Fast-Greedy"><a href="#Fast-Greedy" class="headerlink" title="Fast Greedy"></a>Fast Greedy</h4><p>Fast Greedy将每个节点看作是一个社团，每次迭代选择产生最大Q值的两个社团合并，直至整个网络融合成一个社团。整个过程可表示成一个树状图，从中选择Ｑ值最大的层次划分得到最终的社团结构。该算法的总体时间复杂度为Ｏ(ｍ(ｍ＋ｎ))。</p>
<h4 id="Multi-Level"><a href="#Multi-Level" class="headerlink" title="Multi Level"></a>Multi Level</h4><p>优化了层次聚类方法，将聚类划分为粗化阶段，划分阶段，和细化阶段。首先使用一系列规模逐渐减小的粗化聚类算法，得到能较为完好的保持原始数据特征的粗化类别，在对粗类别再进行划分，最终细化阶段对划分进行微调。<br>与传统聚类方法相比，多层次聚类一般效率更高，并且效果更好（可能会更好的解决，参数过多、鲁棒性差等问题）。</p>
<h3 id="计算网络的连边紧密度Edge-Betweenness"><a href="#计算网络的连边紧密度Edge-Betweenness" class="headerlink" title="计算网络的连边紧密度Edge Betweenness"></a>计算网络的连边紧密度Edge Betweenness</h3><p>Betweenness的指标，首先计算图中每个节点的最短路径，然后统计每个节点作为最短路径的一个途径节点的次数，将该次数作为最终指标。它衡量的是网络里一个节点占据其他n-1节点间捷径的程度。</p>
<p>Newman借鉴了这个标准，通过计算最短路径包含该连边的个数来分析连边，从而扩展为Edge betweenness指标。定义了连边的Betweenness后，就可以通过迭代算法来进行社区划分了。具体做法是先计算所有连边的betweenness，然后去除最高值连边，再重新计算，再去除最高值连边，如此反复，直到网络中的所有连边都被移除。在这个过程中网络就逐渐被切成一个个越来越小的component。在这个过程中，我们同样可以用Q-modularity来衡量社区划分的结果。这种算法定义比较清晰，也不涉及矩阵数学等运算，但问题是计算复杂度比较大。</p>
<h3 id="计算网络拉普拉斯矩阵的特征向量Leading-Eigenvector"><a href="#计算网络拉普拉斯矩阵的特征向量Leading-Eigenvector" class="headerlink" title="计算网络拉普拉斯矩阵的特征向量Leading Eigenvector"></a>计算网络拉普拉斯矩阵的特征向量Leading Eigenvector</h3><p>Leading Eigenvector定义了Laplace矩阵 L = D - A，其中A为网络G的邻接矩阵，D为\(N \times N\)对角为每个节点度数的对角矩阵。<br>Laplace矩阵是对称半正定的，直观上来说L矩阵存在为0的特征值（行列和为0，度与临界关系抵消，L乘以1向量结果为0）。<br>定义最小特非0征值\(\lambda _1\)为代数连通性（algebraic connectivity），对应的特征向量为Fidler vector。特征向量里的每一个元素对应了一个节点，例如Fidler vector=[0.29, 0.00, 0.29, 0.29, 0.29, -0.58, -0.58, 0.00]可以对应{a:0.29, b: 0.00, c:0.29, d:0.29, e:0.29, f:-0.58, g:-0.58, h:0.00}根据数值，我们可以将社群划分为{{a, c, d, e}, {b, h}, {e, f}}。<br>Leading Eigenvector利用了最小特征值来对节点进行划分，实际上可以理解为，利用了特征空间上最弱的特征维度，对边进行划分。事实上，这种划分是相对较弱的，因为只考虑了一阶最弱特征，而实际上社群关系，或在别的特征方向上有明显区分，也可能存在高阶联系。</p>
<h2 id="流分析"><a href="#流分析" class="headerlink" title="流分析"></a>流分析</h2><h3 id="随机游走算法Walk-Trap"><a href="#随机游走算法Walk-Trap" class="headerlink" title="随机游走算法Walk Trap"></a>随机游走算法Walk Trap</h3><p>Walk Trap使用两点到第三点的流距离之差来衡量两点的相似性，从而进行社区划分：</p>
<script type="math/tex; mode=display">
P=D^{-1}A \\\\
r _{ij} = \sqrt{\sum _{k=1} ^n \frac{(P _{ik} ^t - P _{jk} ^t)^2}{d(k)}} = ||D ^{-1/2}P _{i \cdot} - D ^{-1/2}P _{j \cdot}||</script><p>1式表示对邻接矩阵进行归一化，得到的转移矩阵。<br>2式表示为两点间的距离公式。<br>可以看到Walk Trap使用了t阶转移矩阵，即使用了t个时刻后点的转移概率。这里t如果取之过大，根据马尔可夫随机过程的性质可知，P的t阶矩阵将趋于度数矩阵，这时游走的拓扑信息相当于被抹去，因此t不能取值过大，一般取3-5之间。<br>通过扩展转移矩阵，从计算点扩展到计算社群，可以得到社群间的相似度。在得到相似度之后，通过简单聚类，就可以得到社群。</p>
<h3 id="标签扩散算法label-propagation"><a href="#标签扩散算法label-propagation" class="headerlink" title="标签扩散算法label propagation"></a>标签扩散算法label propagation</h3><p>给全网每个节点分配一个不重复的标签（label），在迭代的每一步，让一个节点采用在它所有的邻居节点中最流行的标签（如果最佳候选标签超过一个，则在其中随机抽一个）。最后，在迭代收敛时，采用同一种标签的节点被归入同一个社区。 这个算法的核心是通过标签的扩散来模拟某种流在网络上的扩散。其优势是算法简单，特别适用于分析被流所塑造的网络。在大多数情况下可以快速收敛。其缺陷是，迭代的结果有可能不稳定，尤其在不考虑连边的权重时，如果社区结构不明显，或者网络比较小时，有可能所有的节点都被归入同一个社区。</p>
<h3 id="流编码算法-the-Map-Equation"><a href="#流编码算法-the-Map-Equation" class="headerlink" title="流编码算法 the Map Equation"></a>流编码算法 the Map Equation</h3><p>其核心思想是，好的社区划分要令网络上流的平均描述长度最短，通过编码每一个节点，从而找到能使编码后信息墒最小的社区划分。<br>这里编码主要使用了两层霍夫曼编码，每个社区内部维持一个社区内部局部编码，社区间间区分通过编码社区间的连边的全局社区出口码表。这样一条流，可以用较少的编码来进行表示。<br>在实际生成编码时，通过使用信息墒，来优化编码，初始时，每个节点看作独立节点，接着随机采样出一个序列，依次尝试将每个节点付给邻居节点所在社区，取平均信息下降最大的社区赋予该节点，通过迭代得到社区划分。</p>
<h3 id="流层级算法-Role-based-Similarity"><a href="#流层级算法-Role-based-Similarity" class="headerlink" title="流层级算法 Role-based Similarity"></a>流层级算法 Role-based Similarity</h3><p>通过对网络的邻接矩阵A进行分析，可以得到一个节点从一步到k步的出流或入流的画像（flow profile），在任意两个节点之间比较这种流画像，就可以得到节点之间的相似性，从而为社区划分服务。<br>在计算节点的流入流出画像时，我们认为转移矩阵的一行，即为流出画像，转移矩阵的一列为流入画像，通过不同阶的转移矩阵，得到不同阶的转移画像，将他们拼接，得到最终的流入流出画像，通过计算不同节点的画像相似度（如利用Cos距离或Manhattan距离得到相似度），从而利用聚类得到社群。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-notes" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liuzhiqi.github.io/blog/2019/10/22/时间序列分析（一）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiqi Liu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiqi Liu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/10/22/时间序列分析（一）/" itemprop="url">时间序列分析（一）单变量时间序列分析</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-10-22T10:12:39+08:00">
                2019-10-22
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<h1 id="一、Background"><a href="#一、Background" class="headerlink" title="一、Background"></a>一、Background</h1><p>在我们对单变量时间序列进行分析时，为了简化模型，我们往往需要预先作出一些假设。<!-- arima、谱分析还是alphabet相关方法，都存在类似的假设，--><br>我们令随机变量序列 \(\{Y_t: t=0,\pm1, \pm2, \pm3,···\}\)为一个随机过程，并将其作为我们所观测的时间序列，整个序列可以看作是 Y 的联合分布。对于一般的时间序列模型，我们可以采用一些相应的统计量来描述整个时间序列（如，Y的联合分布为多元正态的，则一阶和二阶矩就可以确定整个模型），这些模型往往较为简单，但是十分实用。</p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="1-1基本统计量"><a href="#1-1基本统计量" class="headerlink" title="1.1基本统计量"></a>1.1基本统计量</h3><h4 id="均值、方差、协方差"><a href="#均值、方差、协方差" class="headerlink" title="均值、方差、协方差"></a>均值、方差、协方差</h4><p>基础统计量在实际单变量时间序列分析中非常有用，它们不仅可以对时间序列的周期性、平稳性等方面进行分析，甚至还可以辅助确定一些时间序列模型的参数。</p>
<h4 id="均值"><a href="#均值" class="headerlink" title="均值"></a>均值</h4><p>对随机过程 \(Y_t\) ，均值定义如下：</p>
<script type="math/tex; mode=display">\mu _t = E(Y _t), t = 0, \pm 1,  \pm 2,  \pm 3, \cdots</script><h4 id="自协方差"><a href="#自协方差" class="headerlink" title="自协方差"></a>自协方差</h4><script type="math/tex; mode=display">\gamma _{t,s} = Cov(Y _t, Y _s), t,s = 0, \pm 1,  \pm 2,  \pm 3, \cdots</script><p>其中 \(Cov(Y _t, Y _s) = E[(Y _t - \mu _t)(Y _s - \mu _s)] = E(Y _tY _s) - \mu _t\mu _s\)（根据均值定义消去均值乘积）。</p>
<h4 id="自相关函数"><a href="#自相关函数" class="headerlink" title="自相关函数"></a>自相关函数</h4><script type="math/tex; mode=display">\rho _{t,s} = Corr(Y _t,Y _s), t,s = 0, \pm 1,  \pm 2,  \pm 3, \cdots</script><script type="math/tex; mode=display">Corr(Y _t,Y _s) = \frac{Cov(Y _t, Y _s)}{\sqrt{Var(Y _t)Var(Y _s)}} = \frac{\gamma _{t,s}}{\sqrt{\gamma _{t,t}\gamma _{s,s}}}</script><!--
##### 时间间隔下的自相关函数
对与时间间隔k，-->
<h3 id="1-2-平稳性"><a href="#1-2-平稳性" class="headerlink" title="1.2 平稳性"></a>1.2 平稳性</h3><p>对于一切时间间隔k，如果在时间点 \(t_1 , t_2, t_3, \cdots , t_n\)下均有，\(Y_{t_1}, Y_{t_2}, Y_{t_3}, \cdots , Y_{t_n}\)与\(Y_{t_1 -k}, Y_{t_2 -k}, Y_{t_3 -k}, \cdots , Y_{t_n -k}\) 的联合分布相同，则过程\(\{Y_{t}\}\)称为<strong>严平稳的</strong>。<br>而若序列是平稳性的，则：<br>当 n=1 时，\(Y_{t}\) 与\(Y_{t-k}\) 的分布相同，所以Y序列的每一点具有相同的分布，因此序列均值与方差恒为常数。<br>进而任意时间点t来说，由于序列的每一点均值方差均相同，所以我们可以化简自相关函数，即</p>
<script type="math/tex; mode=display">\rho _{k} = Corr(Y _t,Y _{t-k}),   \gamma _{k} = Cov(Y _t, Y _{t-k})</script><p>严平稳性是一个非常强的假设，因此我们引出了弱（二阶矩）平稳性：  </p>
<ol>
<li>均值函数在所有时间上恒为常数。   </li>
<li>对于所有时间点t和时间间隔k，有\(\gamma_{t,t-k}=\gamma_{0,k}\)。<br>在实际应用中，\(\gamma_{k}\)是一个非常有用的工具，它可以帮助我们判断时间序列的周期性，在某些时间序列模型中，我们使用\(\gamma_{k}\)来帮我们判断模型参数，这些应用即使在非平稳的状态下也有一定借鉴意义。</li>
</ol>
<h2 id="基本模型"><a href="#基本模型" class="headerlink" title="基本模型"></a>基本模型</h2><p>在进行单变量时间序列分析时，我们往往需要对时间序列模型作出一些假设。最常见的假设为线性叠加模型，即模型中各个组成部分是以线性叠加的方式组合到一起的。对于能预测的单变量模型来说，我们往往认为其具有平稳周期性，和非平稳部分。而非平稳部又可以分为趋势部分与局部异常部分。</p>
<h3 id="周期性"><a href="#周期性" class="headerlink" title="周期性"></a>周期性</h3><p>在单变量时间序列模型中，我们往往假设模型是具有周期性的，在对用户数据建模时，这一点往往是成立的（比如：分析用户PV、UV等，往往具有明显的7天周期与一年周期，在这不同周期中，用户数据整体波动出现明显相似的变化）。<br>对于这一部分的建模，有很多方式，如：简单季节性模型根据周期性的经验估计直接建立模型，ARIMA中利用假设过去周期性的时间节点对当前时间点存在残留影响来建立模型，谱分析对时间序列进行傅立叶变换从而拟合周期部分等等。<br>不论是使用什么方式，在进行周期性估计时，我们往往不考虑序列的整体趋势，也就是说我们认为周期性部分是平稳的（往往只需要弱平稳即可）。</p>
<h3 id="非平稳部分"><a href="#非平稳部分" class="headerlink" title="非平稳部分"></a>非平稳部分</h3><h4 id="趋势"><a href="#趋势" class="headerlink" title="趋势"></a>趋势</h4><p>对于时间序列模型，我们往往可以将其拆分为两部分，一部分是趋势拟合部分，另一部分是周期性拟合部分。对于趋势部分，一些模型是进行单独拟合的，例如：使用线性模型，或根据经验，使用相应的非线性模型，也有一些模型使用了差分的方式，消除趋势对周期性判断对影响（例如：ARIMA）。<br>当然也有一些模型不需要对趋势进行单独拟合，模型可以自动学习出整体趋势与周期特征（例如：使用深度学习方法对序列进行拟合）。</p>
<h4 id="干预与异常"><a href="#干预与异常" class="headerlink" title="干预与异常"></a>干预与异常</h4><p>干预分析（Intervention Analysis）是指在时间序列中，因为在某一时刻发生了自然产生或人为施加的影响，导致整体序列产生了一定时间内均值或趋势发生了相应的变化，例如：外部广告投放导致一定时间内某应用UV突然增长，一段时间后稳定用户有一个明显的数量提升、商家在某一天投放广告导致商品购买量提升，广告停止投放，几天内购买量下降，但仍高于投放前，直至平稳、双十一大促，大促时购买量激增，但大促后用户消费明显疲软，一段时间后恢复正常等。在实际数据中，不同的干预可能有不同的特征，下文将介绍几种简单常见的干预拟合方式。</p>
<p>产生干预时，我们的干预部分用\(S_t ^{(T)}\)表示，其中T为干预产生的时间点。则我们可以定义脉冲函数即：</p>
<script type="math/tex; mode=display">P _t ^{(T)}=S _t ^{(T)}-S _{t-1} ^{(T)}</script><h5 id="阶梯干预"><a href="#阶梯干预" class="headerlink" title="阶梯干预"></a>阶梯干预</h5><p>我们可以将阶梯干预用如下阶梯函数表示：</p>
<script type="math/tex; mode=display">
S _t=\begin{cases}
1,\quad x\geq T \\\\
0,\quad x<T
\end{cases}</script><p>对应的脉冲函数\(P_t ^{(T)}\)，当t=T时\(P_t ^{(T)}\)等于1，其他时间为0。<br>此时我们干预对<em>时间序列均值的叠加部分\(m_t\)</em>为：</p>
<script type="math/tex; mode=display">m _t = \omega S _t ^{(T)} \tag{1.1}</script><p>也就是说在T时刻激增并保持不变，这种干预往往可以看作是一种可加异常，也就是说当前时刻的异常并不影响之后的序列。</p>
<h5 id="逐渐平稳的阶梯干预"><a href="#逐渐平稳的阶梯干预" class="headerlink" title="逐渐平稳的阶梯干预"></a>逐渐平稳的阶梯干预</h5><p>阶梯干预的形式非常理想，但实际应用中，全部影响作用其实会持续很长一段时间最终趋于稳定。我们可以对\(m_t\)建立一个AR(1)模型（后续会对其进行介绍）：</p>
<script type="math/tex; mode=display">
m _t=\begin{cases}
\omega\frac{1-\delta ^{t-T}}{1-\delta},\quad x\geq T \\\\
0,\quad other
\end{cases}</script><p>其中0&lt;\(\delta\)&lt;1。此时<br>均值增量在会在一段时间内激增最终收敛到\(\frac{\delta}{1-\delta}\)，其中达到极限的一半所用时间\(log(0.5)/log(\delta)\)被称为干预的<strong>半衰期</strong></p>
<h5 id="逐渐消失的干预"><a href="#逐渐消失的干预" class="headerlink" title="逐渐消失的干预"></a>逐渐消失的干预</h5><p>对于一些干预，在干预瞬间，序列均值会激增，但随着时间推移这种干预影响会逐渐消失。令T时刻干预产生，这时当t=T时\(P_t ^{(T)}\)等于1，其他时间为0。我们可以将这种干预混入我们的模型例如，混入AR(1)模型中：</p>
<script type="math/tex; mode=display">m _t=\delta m _{t-1} + \omega P^{(T)} _{t-1}</script><p>此时T时刻产生的干预成指数级衰减。</p>
<h5 id="判断与检验"><a href="#判断与检验" class="headerlink" title="判断与检验"></a>判断与检验</h5><p>受到干预或异常的数据，有很多表示方法，针对不容模型，可能表示形式也不尽相同，而上述方法对于ARIMA模型是适用的，对于其他模型则要因模型而异。面对可能的异常，我们需要进行判断和检验，常用的方法可以使用先猜测异常，然后修正模型，进行假设检验，通过反复修正，最终直至不再发现异常为止。<br>在进行检验时，常用多重检验，可以使用保守的Bonferroni矫正（如果在同一数据集上同时检验n个独立的假设，那么用于每一假设的统计显著水平，应为仅检验一个假设时的显著水平的1/n。）控制多重检验的总体误差率。</p>
<h1 id="ARIMA（自回归差分滑动平滑方法）"><a href="#ARIMA（自回归差分滑动平滑方法）" class="headerlink" title="ARIMA（自回归差分滑动平滑方法）"></a>ARIMA（自回归差分滑动平滑方法）</h1><p>对于时间序列\(\{Y _t\}\)，若我们令\(\{e _t\}\)代表一系列未观测到的白噪声序列数据，若我们将其看作一系列独立同分布的均值为0的随机变量。则对于一个序列而言，我们可以将其转化为过去时间点序列值残留的影响与当前时间点白噪声的叠加。<br>因此，对于我们可以将上述过程，简化成一个简单的线性过程：</p>
<script type="math/tex; mode=display">Y _t=e _t + \psi _1 e _{t-1} + \psi _2 e _{t-2} + \cdots \tag{2.1}</script><p>也就是说当前时间点是过去时间点的残留影响加上当前时间点点白噪声。对于这一模型，若表达式右边是一个无穷级数项，则要求：</p>
<script type="math/tex; mode=display">\sum _ {i=1} ^ \infty {\psi _i ^2} < \infty</script><p>也就是说我们希望整体序列整体是收敛的。显然，我们希望考虑到过去的影响，但又不希望过去对当前的影响是发散的。 </p>
<h2 id="MA"><a href="#MA" class="headerlink" title="MA"></a>MA</h2><p>对于公式2.1，若\(\psi \)的数量有限且不为0个，则我们称：</p>
<script type="math/tex; mode=display">Y _t=e _t - \theta _1 e _{t-1} - \cdots - \theta _n e _{t-q}</script><p>为q阶滑动平均过程，简记MA(q)，其中为方便后续公式表达，我们用\(-\theta\)。<br>对于MA(q)过程我们有：</p>
<script type="math/tex; mode=display">\gamma _0 = (1 + \theta _1 ^2 + \theta _2 ^2 + \cdots + \theta _n ^2)\delta _e ^2</script><script type="math/tex; mode=display">
\rho _k=\begin{cases}
\frac{-\theta _k + \theta _1 \theta _{k+1} + \theta _2 \theta _{k+2} + \theta _{q-k} \theta _{q}}{1+\theta _1 ^2+\theta _2 ^2 + \cdots + \theta _q ^2},\quad k=1,2,\cdot,q \\\\ 
0,\quad k>q
\end{cases}</script><h2 id="AR"><a href="#AR" class="headerlink" title="AR"></a>AR</h2><p>对于时间序列\(\{Y _t\}\)若满足方程：</p>
<script type="math/tex; mode=display">Y _t=\phi _1 Y _{t-1} + \phi _2 Y _{t-2} + \cdots + \phi _n Y _{t-p} + e _t</script><p>则，我们称其为p阶自回归过程。从方程我们可以看出，自回归过程是用自身序列做回归变量。对于t时刻的\(Y _t\)来说其值等于过去p个时间点与当前时间点噪声\(e _t\)的加权叠加，其中\(e _t\)要求与t时刻前的Y独立。从等式2.2我们可以看出，通过将右侧Y展开，我们可以还原出等式2.1的形式，但参数的表达可能十分复杂，同时该序列项数可能趋于无穷大。<br>对于MA模型来说，我们较容易保证其平稳，而对于AR模型，平稳显然需要满足条件。令，</p>
<script type="math/tex; mode=display">\phi(x)=1 - \phi _1 x - \phi _2 x^2 - \cdots - \phi _p x ^ p</script><script type="math/tex; mode=display">0=1-\phi _1 x - \phi _2 x^2 - \cdots - \phi _p x ^ p</script><p>为AR模型的特征多项式和特征方程。若特征方程存在平稳解，当且仅当AR特征方程每一个根的绝对值都大于1。因此有如下必要不充分的条件：</p>
<script type="math/tex; mode=display">\phi _1 + \phi _2 + \cdots + \phi _p < 1</script><script type="math/tex; mode=display">| \phi _p |< 1</script><p>假定序列平稳且均值为0。则，我们可以在AR模型方程两边同时乘以\(Y _{t-k}\)并求期望，再除以\(\gamma _0\)可以获得以下重要递推关系：</p>
<script type="math/tex; mode=display">\rho _k=1 - \phi _1 \rho _{k-1} - \phi _2  \rho _{k-2} - \cdots - \phi _p  \rho _{k-p}</script><p>分别将\(k = 1,2,\cdots,p\)带入上述方程，则可以得到方程组（Yule-Walker方程组）通过求解相应方程，我们可以求的任意自相关系数\(\rho <em>k\)。<br>对于AR模型而言，若序列平稳，通过对自回归进行逐层展开，我们可以将其还原为式2.1形式。<br>而对于MA模型，我们可以通过\(Y </em>{t-k}\) 迭代消去序列中的第k项(e _{t-k}\),从而将MA模型转化为AR模型。若原时间序列是无穷的，那么我们最终可能转化为一个无穷阶的AR模型。这种MA可逆的转化是有条件的，需要MA特征方程：</p>
<script type="math/tex; mode=display">0=1-\theta _1 x - \theta _2 x^2 - \cdots - \theta _p x ^ p</script><p>的根的模大于1（类似AR模型平稳性条件）。</p>
<h2 id="ARMA-p-q-模型"><a href="#ARMA-p-q-模型" class="headerlink" title="ARMA(p,q)模型"></a>ARMA(p,q)模型</h2><p>若序列心中一部分是自回归，一部分是滑动平均的，那么我们可以得到一个相当普遍的时间序列模型。如下：</p>
<script type="math/tex; mode=display">Y _t=\phi _1 Y _{t-1} + \phi _2 Y _{t-2} + \cdots + \phi _n Y _{t-p} + e _t - \theta _1 e _{t-1} - \theta _2 e _{t-2} - \cdots - \theta _q e _{t-q}</script><p>对于该模型而言，MA部分我们可以保证解的平稳，因此对于模型整体平稳性，我们只需要保证AR部分过程平稳，即保证模型中AR特征方程根的模大于1。<br>此时模型可以由下式决定：</p>
<script type="math/tex; mode=display">
\left\\{
\begin{array}{l}
\psi _0 = 1\\\\
\psi _1 = -\theta _1 + \phi _1\\\\
\psi _2 = -\theta _2 + \phi _2 + \phi _1\theta _1\\\\
\cdots\\\\
\psi _j = -\theta _j + \phi _p\theta _{j-p} + \phi _{p-1}\theta _{j-p+1} + \cdots + \phi _1\theta _{j-1} \\\\
\end{array}
\right.</script><p>这里我们将模型中AR部分展开得到公式2.1的形式，其中参数\(\psi\)为2.1中系数。<br>对于ARMA模型，我们通常要求AR和MA分别满足平稳和可逆两个条件（上文提到，各自特征方程根模大于一）</p>
<h2 id="非平稳模型"><a href="#非平稳模型" class="headerlink" title="非平稳模型"></a>非平稳模型</h2><p>上述描述的AR与MA模型都存在平稳的前提，而实际上，我们的时间序列往往具有趋势。这时我们可以不再使用的时间序列\(\{Y<em>t\}\)本身来进行预测，而使用查分的方式用变化率作为序列来进行预测。如：\( \Delta Y _t = Y _t - Y </em>{t-1} \)为序列 \(\{Y _t\}\)的一阶差分。</p>
<p><img src="/home/picture/不同阶差分.png" alt="avatar"></p>
<p>如果一个时间序列 \(\{Y _t\}\)的d次差分 \(W _t = \Delta ^d Y _t\)是一个平稳的ARMA(p,q)过程，则称\(\{Y _t\}\)为自回归滑动平均求和模型ARIMA(p,d,q)。通常取d=1或最多2。<br>考虑ARIMA(p,1,q)，令\(W _t = \Delta ^d Y _t\)，我们有：</p>
<script type="math/tex; mode=display">W _t=\phi _1 W _{t-1} + \phi _2 W _{t-2} + \cdots + \phi _n W _{t-p} + e _t - \theta _1 e _{t-1} - \theta _2 e _{t-2} - \cdots - \theta _q e _{t-q}</script><p>通过将W用Y替换并合并，可得：</p>
<script type="math/tex; mode=display">Y _t=(1 + \phi _1)W _{t-1} + (\phi _2 -\phi _1)W _{t-2} + \cdots +  (\phi _{t-p} -\phi _{t-p-1}) W _{t-p} - \phi _p W _{t-p-1} \\\\+ e _t - \theta _1 e _{t-1} - \theta _2 e _{t-2} - \cdots - \theta _q e _{t-q}</script><p>我们称上述形式为模型的差分方程形式。我们分析其AR特征方程：</p>
<script type="math/tex; mode=display">1-(1+\phi _1)x-(\phi _2 - \phi _1)x ^2-\cdots-(\phi _{t-p} -\phi _{t-p-1})x ^p + \phi _p x ^{p+1}=(1-\phi _1 -\phi _2x ^2-/cdots-\phi _px ^p)(1-x)</script><p>此时 x=1是一个根，因此这个过程非平稳，但其余的根是平稳过程\( \Delta ^d Y _t\)的特征多项式的根。这也说明了为什么当原序列非平稳，我们使用一阶差分来得到平稳序列的原因。</p>
<p>差分是实现平稳较好的方式，出了差分外，我们还可以根据序列特征对序列进行其他的变换。例如：如果发现序列散度随着时间增加，可以尝试使用对数方法对序列进行变换等。</p>
<h2 id="季节性ARIMA"><a href="#季节性ARIMA" class="headerlink" title="季节性ARIMA"></a>季节性ARIMA</h2><p>对于普通的ARIMA模型，我们考虑的是当前相近的时间节点对现在的影响，然而实际上数据的周期可能会更长。例如：对于用户数据而言，往往存在以周和年为周期的pattern。对于这种较长跨度的周期性影响，ARIMA模型不能进行很好的表达，这时我们可以引入季节性ARIMA模型。<br><strong>简单的季节性ARIMA模型</strong>我们可以通过经验知识，选出相应周期，考虑序列影响时，只考虑倍数于周期的相应时间节点。例如以s（s大于P和Q）为周期，则我们的AR(P)和MA(Q)以及差分I(D)模型如下：</p>
<script type="math/tex; mode=display">
Y _t = Y _t - \Phi _1Y _{t-s}  - \Phi _2Y _{t-2s} - \cdots - \Phi _PY _{t-Ps}</script><script type="math/tex; mode=display">
Y _t = e _t - \Theta _1e _{t-s}  - \Theta _2e _{t-2s} - \cdots - \Theta _Qe _{t-Qs}</script><script type="math/tex; mode=display">
\Delta _s Y _t = Y _t + Y _{t-s}</script><p>可以看到AR、MA、以及差分，我们都只考虑不同周期s上相同位置的时间节点（只考虑最近P和Q个周期内的时刻）。注意这里我们使用参数：\(P,Q,\Phi,\Theta\)均为大写以表示季节模型。<br>简单季节性ARIMA加入引入一个周期s，整体模型可以看作是对时间序列间隔s时刻，从而抽出s个子序列，并使用普通ARIMA模型进行拟合。然而这种方法只考虑了一个固定周期的影响，实际上真实序列相近时刻可能也会对当前时刻造成影响（基本的ARIMA模型的假设），因此我们需要同时考虑季节性影响和临近影响。因此引入了人<strong>乘法季节ARIMA模型</strong>。<br>乘法季节ARIMA模型结合了季节和非季节ARIMA，利用类似卷积的思路，将二者结合。例如：我们考虑结合\(MA(1)\) 与 \(MA(1) _s\)两个模型，得到如下特征多项式：</p>
<script type="math/tex; mode=display">
(1 -\theta x)(1-\Theta x ^{12}) = 1 - \theta x - \Theta x ^{12} - \theta\Theta x^{13}</script><p>通过特征多项式我们可以写出相应的时间序列表达式：</p>
<script type="math/tex; mode=display">
Y _t = e _t - \theta e _{t-1} - \Theta e _{t-12} - \theta\Theta e _{t-13}</script><p>因此我们定义周期为s的乘法季节\(ARMA(p,q)\times(P,Q) _s\)模型，通过分别求AR特征多项式\(\phi\Phi(x)\)和MA特征多项式\(\theta(x)\Theta(x)\)得到相应AR与MA模型序列通过相加合并两个子模型。<br>对于差分模型而言我们可以定义混合差分操作：</p>
<script type="math/tex; mode=display">
W _t = \Delta ^d \Delta _s ^D Y _t</script><p>因此我们可以得到新的季节ARIMA模型：\(ARMA(p,d,q)\times(P,D,Q) _s\)</p>
<h2 id="模型识别"><a href="#模型识别" class="headerlink" title="模型识别"></a>模型识别</h2><h3 id="k阶滞后自相关函数（ACF）"><a href="#k阶滞后自相关函数（ACF）" class="headerlink" title="k阶滞后自相关函数（ACF）"></a>k阶滞后自相关函数（ACF）</h3><p>回顾第一节，我们有k阶滞后的自相关函数:</p>
<script type="math/tex; mode=display">
\rho _{k} = Corr(Y _t,Y _{t-k}) = \frac{Cov(Y _t, Y _{t-k})}{\sqrt{Var(Y _t)Var(Y _{t-k})}} = \frac{\gamma _{k}}{\gamma _{0}}</script><script type="math/tex; mode=display">
\gamma _{k} = Cov(Y _t, Y _{t-k}) = \frac{\sum _{t=k+1} ^{n} {(Y _t - \overline{Y})(Y _{t-k} - \overline{Y})} }{\sum _{t=1} ^n {(Y _t - \overline{Y}) ^2}}  k=1,2,\cdots</script><p>对于MA(q)模型而言当k&gt;q时，\(\rho _k = 0\)，这里r为\(\rho \)的估计量。因此对于MA模型而言我们可以使用K阶之后自相关函数确定起q的取值。</p>
<h3 id="k阶滞后偏自相关函数（PACF）"><a href="#k阶滞后偏自相关函数（PACF）" class="headerlink" title="k阶滞后偏自相关函数（PACF）"></a>k阶滞后偏自相关函数（PACF）</h3><p>对于AR模型而言，由于模型往往可以展开成无穷阶MA模型，因此k阶滞后自相关函数不适用。从另一方面考虑，若我们希望计算\(Y <em>{t-k} \)对\(Y _t \)的影响程度从而判断模型是否含有第k阶，直接计算\(Y </em>{t-k} \)与\(Y <em>t \)的相关性是不合理的，这是因为对于\(Y _t \)而言其自身还包含了<br>\(Y  </em>{t-1},Y <em>{t-2}, \cdots ,Y </em>{t-k+1} \)项。因此我们考虑消除\(Y <em>t \)中的<br>\(Y  </em>{t-1},Y <em>{t-2}, \cdots ,Y </em>{t-k+1} \)影响后，再计算消除影响后的\(Y <em>t \)与\(Y </em>{t-k} \)的相关系数，我们称这个系数为<strong>k阶滞后偏自相关系数</strong>。<br>由于AR模型为回归方法，为了达到消除影响的目的，因此我们可以考虑先对序列进行拟合，然后为了计算得到样本的k阶滞后偏自相关函数。对\(Y <em>t \)我们使用\(Y  </em>{t-1},Y <em>{t-2}, \cdots ,Y </em>{t-k+1} \)项进行预测： </p>
<script type="math/tex; mode=display">
Y _t=</script><p>对\(\beta \)我们可以使用均方误差最小化，利用最小二乘法估计。<br>对于\(Y _{t-k} \)，我们可以利用t-k之后的k-1个项来进行向前预测，由序列平稳可得（？？？）：</p>
<script type="math/tex; mode=display">
Y _k=\beta _1 Y _{t-K+1} + \beta _2 Y _{t-K+2} + \cdots + \beta _{k-1} Y _{t-1}</script><p>因此我们定义<strong>K阶偏子相关系数</strong>为预测误差之间的相关系数：</p>
<script type="math/tex; mode=display">
\phi _{kk}=Corr(Y _t - \beta _1 Y _{t-1} - \beta _2 Y _{t-2} - \cdots - \beta _{k-1} Y _{t-k+1},  \\\\
Y _{t-k} - \beta _1 Y _{t-K+1} - \beta _2 Y _{t-K+2} - \cdots - \beta _{k-1} Y _{t-1}  )</script><p>对于若序列服从AR(p)模型，显然当预测的模型为p项时，对模型的预测将最准确，此时k阶之后偏子相关系数有：</p>
<script type="math/tex; mode=display">
\phi _{kk} = 0, k>p</script><p>而对于MA模型来说，其偏自相关函数从不为0，但随着滞后的增加，会指数级快速衰减到0。这一点与AR(1)过程的子相关函数类似。<br>对于K阶偏自相关系数，我们可以用最小二乘法分别求不同阶的预测模型，然后再求其相关系数。同时我们也可以使用Yule-Walker方程来进行求解。<br>具有自相关函数\(\rho _k\)的任意平稳过程，对于k阶滞后，我们有：</p>
<script type="math/tex; mode=display">
\rho _j = \phi _{k1} \rho _{j-1} +\phi _{k2} \rho _{j-2} +\phi _{k3} \rho _{j-3} + \cdots+\phi _{kk} \rho _{j-k} , j=1,2,\cdots,k</script><p>我们可以先算出各阶\(\rho\)然后带入方程组从而求解出\(\phi <em>{k1},\phi </em>{k2},\cdots,\phi <em>{kk} \)，这里我们只需要最后一项。对于不同阶k，反复求解方程组从而得到\(\phi </em>{kk}\)，我们有\(\phi _{kk}\)递归方程：</p>
<script type="math/tex; mode=display">
\phi _{kk} = \frac{\phi _{k} - \sum _{j=1} ^{k-1}{\phi _{k-1,j}\rho _{k-j}}}{1 - \sum _{j=1} ^{k-1}{\phi _{k-1,j} \rho _{j}}}</script><p>对于大于p时样本偏自相关函数近似服从均值为0，方差为1/n的正态分布. 因此，当 k&gt;p 时，我们可以用\(\pm 2/\sqrt{n}\)作为\(\hat \phi _{kk}\)的临界极值来检验AR(p)模型的正确0假设。</p>
<h2 id="非平稳性"><a href="#非平稳性" class="headerlink" title="非平稳性"></a>非平稳性</h2><p>在实际使用ARIMA模型时，我们往往仅使用1～2阶差分，过度的差分，会导致差分后的序列产生不必要的相关性，从而使模型变得复杂，最终导致过拟合。同时过度差分还可能导致差分后序列模型不可逆。<br>在对差分阶数进行判断时，ACF仍然是一个非常好用的工具。如果ACF的图像呈现明显近似线性的衰减，说明非平稳性影响了序列的自相关性。此时序列需要进行差分。更具体的方法还有Dickey-Fuller单位根检验（检验AR方程是否存在单位根）等。</p>
<h3 id="ARIMA模型的判别"><a href="#ARIMA模型的判别" class="headerlink" title="ARIMA模型的判别"></a>ARIMA模型的判别</h3><p>对于ARMA模型来说，由于ACF和PACF都只能针对AR或MA其中一个模型进行判别，若二者混合，不能很好判别。因此我们引入了一些扩展的方法来识别。</p>
<h4 id="EACF（扩展自相关法）："><a href="#EACF（扩展自相关法）：" class="headerlink" title="EACF（扩展自相关法）："></a>EACF（扩展自相关法）：</h4><p>如果AR模型是已知的，则可以从ARMA模型中去掉自回归部分从而得到一个纯MA过程。</p>
<h4 id="AIC（Akaike’s-Information-Criterion-赤池信息准则）："><a href="#AIC（Akaike’s-Information-Criterion-赤池信息准则）：" class="headerlink" title="AIC（Akaike’s Information Criterion,赤池信息准则）："></a>AIC（Akaike’s Information Criterion,赤池信息准则）：</h4><p>AIC要求模型最小化：</p>
<script type="math/tex; mode=display">
AIC = -2\log {(D(p,q _\theta))+2k}</script><p>如果模型包含常数项或者截距项，则k=p+q+1，否则k=p+q。<br>AIC是估计模型与真实模型等平均KL偏离度的估计量。另\(p(y <em>1,y _2,\cdots,y _n)\)是\(Y _1,Y _2,\cdots,Y _n\)的真实pdf，\(q </em>\theta(y _1,y _2,\cdots,y _n)\) 是参数为 \(\theta\)的模型相应的pdf。则q和p的KL偏离由下面公式定义：</p>
<script type="math/tex; mode=display">
D(p,q _\theta) = \int _{-\infty} ^{\infty} \int _{-\infty} ^{\infty} \cdots\int _{-\infty} ^{\infty}{p(y _1,y _2,\cdots,y _n) \log{[\frac{p(y _1,y _2,\cdots,y _n)}{q _\theta(y _1,y _2,\cdots,y _n)}]}}dy _1dy _2\cdots dy _n</script><p>AIC估计了\(E(D(p,q _\hat \theta))\)，这里\(\hat \theta\)是参数\(\theta\)的极大似然估计。但是AIC是有偏估计量，若参数数量和数据容量的比率较大，则偏差会很大。因此引入\(AIC _c\)方法对AIC进行修正：</p>
<script type="math/tex; mode=display">
AIC _c = AIC + \frac{2(k+1)(k+2)}{n-k-2}</script><p>其中n是样本容量，k是出去噪声方差后的总参数量，当k/n&gt;0.1时，\(AIC _c\)表现优于其他模型选择准则（包括AIC、BIC）</p>
<h4 id="BIC（Bayesian-Information-Criterion-贝叶斯信息准则）："><a href="#BIC（Bayesian-Information-Criterion-贝叶斯信息准则）：" class="headerlink" title="BIC（Bayesian Information Criterion,贝叶斯信息准则）："></a>BIC（Bayesian Information Criterion,贝叶斯信息准则）：</h4><script type="math/tex; mode=display">
BIC =  -2\log {(D(p,q _\theta))+k\log{(n)}}</script><h2 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h2><p>当确定相应的ARIMA阶数后，我们既可以进行参数估计。常用的参数估计有最小二乘法与极大似然函数。</p>
<h3 id="最小二乘法"><a href="#最小二乘法" class="headerlink" title="最小二乘法"></a>最小二乘法</h3><p><span id="e——"></span><br>对于AR模型而言，其满足标准最小二乘法形式，因此用最小二乘法估计十分简单。但对MA模型，由于其中存在e的噪声项，因此无法直接求的，所以我们需要对其进行转换：</p>
<script type="math/tex; mode=display">
e _t = Y _t + \theta _1 e _{t-1}+  \theta _2 e _{t-2} + \cdots +  \theta _{q} e _{t-q}</script><p>其中\(e <em>0 = e </em>{-1}=\cdots=e _{-q} = 0\)，因此：</p>
<script type="math/tex; mode=display">
e _1 = Y _1</script><script type="math/tex; mode=display">
e _2 = Y _2 + \theta _1 e _{t-1}</script><script type="math/tex; mode=display">
e _3 = Y _3 + \theta _1 e _{2}+  \theta _2 e _{1}</script><script type="math/tex; mode=display">
\cdots</script><p>此时，我们最小化目标函数：</p>
<script type="math/tex; mode=display">
S _c (\theta) = \sum{(e _t)^2}</script><p>通过递推的计算\(e <em>1 , e </em>{2} , \cdots , e <em>{q}\)，带入方程组，利用多元数值算法，可以就\(\theta _1 ,\theta </em>{2} , \cdots , \theta _{q}\)联合的求取平方和最小值。<br>对于ARMA(p,q)模型，通过对模型公式进行整理，我们也可以使用同样方法：</p>
<script type="math/tex; mode=display">
e _t = Y _t - \phi _1 Y _{t-1} - \phi _2 Y _{t-2} - \cdots - \phi _p Y _{t-p}  + \theta _1 e _{t-1}+  \theta _2 e _{t-2} + \cdots +  \theta _{q} e _{t-q}</script><p>注意对于大样本而言，初始值\(e <em>{p} , e </em>{p-1},\cdots,e <em>{p-q+1}\)对于可逆模型影响甚。因此这里\(e </em>{p} = e <em>{p-1}=\cdots=e </em>{p-q+1} = 0\),序列从p+1开始递推。</p>
<h4 id="自回归逼近法"><a href="#自回归逼近法" class="headerlink" title="自回归逼近法"></a>自回归逼近法</h4><p>自回归逼近法，先将数据看做纯\(AR(\hat p)\)模型，利用AIC定阶确定\(\hat p\)，利用最小二乘法估计出相应的参数。用得到的\(AR(\hat p)\)模型对序列进行一步预测得到预测变量\(\hat Y _t\)，从而进一步估计出\(\hat e _t = Y _t - \hat Y _t\)。将得到的\(\hat e _t \)与真实数据\( Y _t\) 带入ARMA模型，于是就可以使用最小二乘法直接对AR与MA的参数进行估计。</p>
<h3 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h3><p>对于最小二乘法，我们利用了分布的一阶矩和二阶矩，而对于最大似然法，我们使用了数据的全部信息。<br>模型定阶完成后，对于ARIMA(p,d,q)实际需要估计的参数有\(\phi,\theta,\mu,\sigma _e\)，对于序列中的\(e _t\)服从于\( Normal(0,\sigma ^2)\)，且彼此独立。因此我们可以得到\(e _2,e _3,\cdots,e _n\)联合概率密度：</p>
<script type="math/tex; mode=display">
(2\pi\sigma _e ^2) ^{-(n-1)/2}exp(-e _t ^2 /2\sigma _e ^2\sum _{t=2} ^{n} e _t ^2)</script><p>ARIMA的极大似然估计法通过逐步递推预测公式导出，极大似然函数，具体过程较为复杂，可以参考PKU李东风老师的备课笔记CH21<sup><a href="#fn_PKUTimeSerious" id="reffn_PKUTimeSerious">PKUTimeSerious</a></sup></p>
<h2 id="模型预测"><a href="#模型预测" class="headerlink" title="模型预测"></a>模型预测</h2><p><span id="e_estimation"></span></p>
<p>在获得模型之后，既可以用模型对未来数据进行预测，对于预测结果，我们同时还可以估计预测的精度。<br>我们令：\(\hat Y _t(l)\)为序列前t项已知状态下对t之后第l项进行预测的预测值。</p>
<h3 id="AR模型的预测"><a href="#AR模型的预测" class="headerlink" title="AR模型的预测"></a>AR模型的预测</h3><p>则对于AR模型而言，有：</p>
<script type="math/tex; mode=display">
\hat Y _t(l) =\sum _{i=1} ^{p} {\phi _i Y _{t+l-i}}\\\\
Y _{t+l-i} = \hat Y _t(l-i) \qquad  when:\quad l-i>0</script><p>可以采用一步预测的方式，从预测\(\hat Y <em>t(1)\)开始逐步递推到l项。<br>可以看到与AR模型相比，预测缺少了\(e </em>{t+l}\) 项。对于一步预测\(\hat Y <em>t(1)\)而言,预测误差\(e _t(1) = Y </em>{t+l} - \hat Y <em>t(l) = e </em>{t+1}\)。<br>对于</p>
<script type="math/tex; mode=display">
\hat e _t(l) =\sum _{i=1} ^{\infty} {\psi _i e _{t+l-i}}\\\\
e _{t+l-i} = 0 \qquad  when:\quad l-i<=0</script><p>其中，\(\psi\)是由AR模型进行MA展开得到的相应参数。<br>因此，\(E(e _t(l)) = 0\)，相应预测估计是无偏估计。对于误差方差：</p>
<script type="math/tex; mode=display">
Var(e _t(l)) = \delta _e ^ 2 (1 + \psi _{1} ^2 + \psi _{2} ^2 + \cdots + \psi _{l-1} ^2 )</script><p>由于我们假设序列平稳，因此这里：</p>
<script type="math/tex; mode=display">
Var(e _t(l)) \approx Var(Y _t) = \gamma _0 , 当l较大时</script><p>证明略，感兴趣的同学，可以尝试使用AR(1)模型进行验证。<br>同时，对于arima模型，若序列非平稳则方差随预测时间窗口l的增大而无限增大。</p>
<h3 id="MA模型的预测"><a href="#MA模型的预测" class="headerlink" title="MA模型的预测"></a>MA模型的预测</h3><p>对于MA模型而言，由于预测模型与e相关，因此需要先对e进行求解。<br>我们使用模型估计时用到的<a href="#e_estimation">递推估计方法</a>，求得\(E(e _{t+l-1}|Y _1,Y _2, \cdots, Y _t)\)。因此，可以得到：</p>
<script type="math/tex; mode=display">
\hat Y _t(l) =\sum _{i=1} ^{p} {\phi _i E(e _{t+l-i} | Y _1,Y _2, \cdots, Y _t)}\\\\
E(e _{t+l-i} | Y _1,Y _2, \cdots, Y _t)  = \left\\{
\begin{array}{l}
0, \qquad when\quad  l-i>0\\\\
e _{t+l-i},\qquad  when \quad l-i<=0\\\\
\end{array}
\right.</script><p>其中对于l-i&gt;0的情况，由于相应的Y值是我们预测得到，因此我们无法通过递推关系求得相应残差的期望，另一方面，我们希望我们的预测尽可能准确，因此另残差期望为零也是合理的。<br>这里值得注意的一点，我们使用递推估计的方法逼近残差，需要满足模型可逆的前提。<br>同时，在对\(E(e _{t+l-1}|Y _1,Y _2, \cdots, Y _t)\)进行估计的时候，因为我们将e序列转化成了无穷序列的Y只和，因此，我们可以考虑，当逼近项数j&gt;t-q时，对应Y的参数项\(\pi _j\)可以忽略。</p>
<h3 id="ARIMA模型的预测"><a href="#ARIMA模型的预测" class="headerlink" title="ARIMA模型的预测"></a>ARIMA模型的预测</h3><p>对arima模型的预测可分为AR部分与MA部分，值得注意的是，若MA的截断j值选取t-q时，当l&gt;q时，ARIMA模型中MA部分将不起作用，因此此时模型只包含AR部分。<br>对ARMA模型，以\(\{e _t\}\)为基进行展开，得到相应参数\(\{\psi _t\}\)，则此时预测对应残差为：  </p>
<script type="math/tex; mode=display">
e _t(l) = Y _{t+1} - \hat Y(l) \\\\
= e _{t+l} + \psi _{1} e _{t+l-1} + \psi _{2} e _{t+l-2} + \cdots + \psi _{l-1} e _{t+1}</script><p>也就是说对于真实的\(Y _{t+l}\)，对l周期内的误差对l点的预测具有累计效应。当序列平稳时，l趋于无穷，序列误差对方差趋于\(\gamma _0 \)。<br>这里由于我们误差服从正态分布，因此通过计算置信区间，利用误差的方差，我们可以对预测结果的范围进行估计。</p>
<h2 id="模型诊断"><a href="#模型诊断" class="headerlink" title="模型诊断"></a>模型诊断</h2><p>为判断学习出的ARIMA模型是否有效，我们需要对得到的模型进行诊断。</p>
<h3 id="残差分析"><a href="#残差分析" class="headerlink" title="残差分析"></a>残差分析</h3><p>对于ARIMA模型，我们假设我们的数据满足模型:</p>
<script type="math/tex; mode=display">Y _t=\pi _1 Y _{t-1} + \pi _2 Y _{t-2} + \cdots + e _{t-q}</script><p>这里假设模型平稳可逆，\(\pi\)是模型差分和MA部分展开并与AR部分合并后得到的合并参数。<br>在模型建立好后，对每一个\(\pi\)，我们有一个估计量\(\hat \pi\)，因此使用过去序列对现在时间点t进行预测后，我们可以得到残差（实际值-预测值）：</p>
<script type="math/tex; mode=display">\hat e _{t-q} = Y _t - \hat \pi _1 Y _{t-1} - \hat \pi _2 Y _{t-2} + \cdots</script><p>如果我们的ARIMA模型预测无误，则\(\hat e <em>{t} = e </em>{t}\)，也就是说我们的残差应：1. 服从正态分布 2. 每一时刻的残差与前序时刻不相关。通过判断残差这两点特性，我们可以分析出ARIMA模型对数据的拟合程度。<br>在实际判别中，我们主要判断方法有：残差图，QQ图，残差自相关性判定，统计量检验等方法。</p>
<h4 id="残差图"><a href="#残差图" class="headerlink" title="残差图"></a>残差图</h4><p>由于残差应近似服从正态分布，因此我们绘制出残差的时间序列散点图（即残差图，X轴为时间，Y轴为残差值），通过比较散点图的随机性，与正态分布的特点来判断其正态性。这里我们可以关注：      </p>
<ol>
<li>在相邻时刻残差是否产生了明显的相关特点. </li>
<li>不同时间段内，残差的变化幅度是否相近. </li>
<li>残差值超过\( 1\sigma, 2\sigma, 3\sigma \)的数量.   </li>
</ol>
<p>如图：</p>
<script type="math/tex; mode=display">此处应有图+解释</script><h5 id="残差正态性与QQ图（分位数-分位数图）"><a href="#残差正态性与QQ图（分位数-分位数图）" class="headerlink" title="残差正态性与QQ图（分位数-分位数图）"></a>残差正态性与QQ图（分位数-分位数图）</h5><p>使用残差图我们可以很好的看出残差在不同时间段是否有特殊的特征，但其对正态分布的实际分布情况并不能完全的刻画，因此我们引入了QQ图（分位数-分位数图）。<br>QQ图横坐标是理论分位数，纵坐标是实际分位数，我们通过算出每一个时刻t，残差在实际残差序列中的分位数位置作为Y轴，其在模型中残差的理论上的高斯分布应处于的分位数位置作为X轴，从而绘制出散点图。如果残差满足正态分布，则其应满足：</p>
<ol>
<li>其散点应该分布在y=x这一条直线上</li>
<li>散点越靠近原点(0,0)点越密集，越远离原点越稀疏。</li>
<li>稀疏变化程度应该与正态分布的分布一致</li>
</ol>
<p>如图：</p>
<script type="math/tex; mode=display">此处应有图+解释</script><h4 id="残差自相关性"><a href="#残差自相关性" class="headerlink" title="残差自相关性"></a>残差自相关性</h4><p>除了残差的正态性，我们还可以从残差相关性入手。通过计算残差序列不同阶的相关性，我们可以画出残差的ACF图。若无相关性，则各阶滞后均应该处于一个较低的水平。通过对相关性显著性分析，我们可以定量的判断模型是否有异常。</p>
<script type="math/tex; mode=display">ACF显著性判断</script><p>如图：</p>
<script type="math/tex; mode=display">此处应有图+解释</script><p>通过观察ACF图，我们可以找到是否有单个的滞后相关性具有异常。而另一方面，我们还可以对各个滞后进行综合考虑，可能单个相关系数没有异常，但是整体来看，具有异常。因此我们引入<strong>Ljung-Box检验</strong>，其统计量为：</p>
<script type="math/tex; mode=display">Q=n(\hat r _1 ^2 + \hat r _2 ^2 + \cdots +\hat r _k ^2 )</script><p>若我们估计的模型正确，则Q应该近似服从自由度为k-p-q的卡方分布，若假设检验不能通过，则可以判断模型拟合有误。5t t</p>
<h3 id="过拟合和参数冗余"><a href="#过拟合和参数冗余" class="headerlink" title="过拟合和参数冗余"></a>过拟合和参数冗余</h3><p>数据缺失<a href="http://rpubs.com/englianhu/handle-missing-value" target="_blank" rel="noopener">http://rpubs.com/englianhu/handle-missing-value</a></p>
<h1 id="谱表示与谱分析"><a href="#谱表示与谱分析" class="headerlink" title="谱表示与谱分析"></a>谱表示与谱分析</h1><p>ARIMA模型主要从滑动窗口和序列自相关性两方面对序列的周期性进行拟合。而考虑到对周期性问题进行拟合，我们很容易想到信号处理中的谱表示，即通过使用不同频率的正弦余弦函数，拟合出我们希望得到的周期变化。同时，我们还引入了傅立叶变换，将序列从空域变换到频域，通过分析频域图像，从而对周期性，相关性等进行更好的分析，这是谱分析的基本思想。</p>
<h2 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="基本公式与概念"><a href="#基本公式与概念" class="headerlink" title="基本公式与概念"></a>基本公式与概念</h3><p>一下为一些简单常用的公式：</p>
<script type="math/tex; mode=display">
R\  cos(2\pi ft + \Phi)=A\ cos(2\pi ft )+B\ sin(2\pi ft)</script><script type="math/tex; mode=display">
R = \sqrt{(A^2 + B^2)},\ \Phi = artan(-B/A)</script><script type="math/tex; mode=display">
B = R * cos(\Phi),\    A = -R * sin(\Phi)</script><p>对于谱表示来说，我们可以将通项公式写成如下形式： </p>
<script type="math/tex; mode=display">
Y  _t  = A _0 + \sum _{j=1} ^m {[A _j cos(2 \pi f _j t) + B _jsin(2 \pi f _j t)]}
\tag{谱1.1}</script><p>这是一种利用正弦余弦对，对时间序列的拟合，对于其中的各项A与B我们可以用最小二乘法进行回归，对于其中频率f 如果我们取特殊形式，则回归将会变得特别简单，例如：<br>1）n=2k+1：<br>则频率为依次为：1/n,2/n,…,k/n (k/n=1/2-1/(2n))。这种频率我们称之为傅立叶频率，在这些频率下，正弦和余弦的预测变量是正交的。<br>因此，最小二乘估计可得：</p>
<script type="math/tex; mode=display">
\hat A _0 = \overline Y</script><script type="math/tex; mode=display">
\hat A _j = \frac{2}{n} \sum _{t=1} ^n {Y _t cos(2 \pi t j/n)},\ \hat B _j = \frac{2}{n} \sum _{t=1} ^n {Y _t sin(2 \pi t j/n)}</script><p>2）n=2k：<br>则：</p>
<script type="math/tex; mode=display">
\hat A _k = \frac{1}{n} \sum _{t=1} ^n (-1) ^t Y _t,\ \hat B _j = 0</script><p>对于任意长度的序列，无论其是确定性的还是随机的，都可以用通项公式进行完美拟合。<br>同时，对于长序列，通常来说可以使用快速傅立叶变换进行快速求解。</p>
<h3 id="周期图"><a href="#周期图" class="headerlink" title="周期图"></a>周期图</h3><p>通过上述通项公式，我们可以对时间序列进行拟合。但实际拟合中，我们需要确定实际需要拟合哪一些周期。这时周期图是一个较好的工具。<br>周期图定义为:</p>
<script type="math/tex; mode=display">
I(j/n) = \frac{n}{2} (\hat A _j ^2 + \hat B _j ^2 )</script><p>对于样本量为偶数时，即 \(n=2k)\)时，在极端频率\(f=k/b=1/2)\)时，有：</p>
<script type="math/tex; mode=display">
I(1/2) = n(\hat A_k)^2</script><p>周期图的高峰显示了序列整体行为中不同频率上余弦-正弦对的相对强度。我们可以选取周期图中峰值较高的周期进行建模。<br>实际上对于一般的时间序列而言，周期图是时间序列从空域向频域变换后频域的图像。<br>对于较长序列，我们可以使用快速傅立叶变换的方式（FFT）进行快速有效的数值计算。</p>
<h2 id="谱表分析"><a href="#谱表分析" class="headerlink" title="谱表分析"></a>谱表分析</h2><h3 id="谱表示"><a href="#谱表示" class="headerlink" title="谱表示"></a>谱表示</h3><p>对于谱分析的通项公式（谱1.1）来说，我们先考虑\(A_0=0\)的情况，又或者说，我们可以移除样本均值，令\(Y _t\)为样本到样本均值的偏差。此时，我们仅考虑\(0&lt;f&lt;1/2\)的情况（ 对于f在(0,1/2)和(1/2,1)区间，图像实际上是重叠的 ）。<br>我们令：  </p>
<script type="math/tex; mode=display">
a(f)=\sum _{\\{j|f _j<f\\}} A _j, b(f)=\sum _{\\{j|f _j<f\\}} B _j</script><p>从而构造出两个阶梯函数。从而我们可以对通项公式进行改写,得到谱表示：</p>
<script type="math/tex; mode=display">
Y _t = \int _0 ^{1/2} cos(2\pi ft) \rm{d}a(f) + \int _0 ^{1/2} sin(2\pi ft)
 \rm{d}b(f) \tag{谱1.2}</script><p><strong>事实上，任何零均值平稳的过程都能表示成上述方程的形式。即，平稳过程可以用连续频带上无穷多个余弦正弦对的线形组合表示。</strong></p>
<h3 id="周期图与谱密度"><a href="#周期图与谱密度" class="headerlink" title="周期图与谱密度"></a>周期图与谱密度</h3><p>正如上文提到的，要分析时间序列，周期图是一个很好的工具。实际上周期图是对谱表示的时间序列过程进行傅立叶变换的频域图像。这里我们引入谱密度（功率谱）概念，一个信号的功率谱密度就是该信号自相关函数的傅里叶变换。谱密度是过程经过傅立叶变换后在频域的密度函数。</p>
<p>平稳随机过程的功率谱是一个确定函数。通过计算我们可以得到其公式为：</p>
<script type="math/tex; mode=display">
S(f)=\gamma_0 + 2\sum _{k=1} ^\infty \gamma _k cos(2\pi fk)</script><p>其中，\(\gamma _k\)为函数的k阶滞后样本协方差。根据傅立叶理论（QA：Planchere定理？是否需要过程满足先决条件，例如函数属于L2空间?），必存在一个相反关系，即：  </p>
<script type="math/tex; mode=display">
\gamma _k = \int _{-1/2} ^{1/2} S(f) cos(2\pi kf) \rm{d}f</script><p>从数学上来讲，S(f)是序列 \(\{\gamma _k\}\)的离散时间傅立叶变换，而 \(\{\gamma _k\}\)是谱密度的傅立叶逆变换。<br>同时还有：</p>
<script type="math/tex; mode=display">
F(f) = \int _{0} ^{f} S(x) \rm{d}x ,0<= f <=1/2</script><p>可以看出，谱密度下方区域面积的两倍是过程方差对应频率区间上构成该过程的余弦正弦对的那部分。<br>对于周期图I(f)，我们有：</p>
<script type="math/tex; mode=display">
\hat{S}(f)=1/2I(f),\hat{S}(1/2)=I(1/2),</script><h3 id="附："><a href="#附：" class="headerlink" title="附："></a>附：</h3><p>傅立叶变换公式：</p>
<script type="math/tex; mode=display">
F(\omega) = \int _{-\infty} ^{\infty} f(t)e^{-i\omega t} \rm{d}t</script><h1 id="综合方法"><a href="#综合方法" class="headerlink" title="综合方法"></a>综合方法</h1><h2 id="Prophet"><a href="#Prophet" class="headerlink" title="Prophet"></a>Prophet</h2><p>prophet是facebook开源的python预测库，该库的api设计与sklearn很像，也是分为fit方法和predict方法。prophet将时间序列分解为三个不同的成分：趋势成分，周期性成分与特殊点（如节假日），并采用加法模型，将三个成分相结合：</p>
<script type="math/tex; mode=display">
y(t)=g(t)+s(t)+h(t)+\epsilon_t</script><p>其中g(t)为趋势函数，代表序列中非周期性的改变，s(t)为周期性成分，h(t)为节假日等特殊点。\(\epsilon _t\) 为随机成分，我们一般令其为正态分布。<br>我们知道对于ARIMA模型而言我们可以利用差分方法来拟合趋势，而利用这种加性模型，对于趋势我们可以更加自由的进行拟合。</p>
<h3 id="趋势拟合"><a href="#趋势拟合" class="headerlink" title="趋势拟合"></a>趋势拟合</h3><p>prophet主要使用了两种趋势拟合模型，增长模型与线性模型</p>
<h4 id="增长模型"><a href="#增长模型" class="headerlink" title="增长模型"></a>增长模型</h4><p>增长模型常被用于生态系统模型中（被广为熟知的增长s曲线）如下：</p>
<script type="math/tex; mode=display">
g(t)=\frac{C}{1+exp(-k(t-m))}</script><p><img src="./time_series1/prophet_growth_curve.png" alt="avatar"></p>
<p>然而在实际使用过程中，这种完美的曲线是不存在的，以用户数据为例：当新功能发布，用户增长率（k）与曲线容量（C）可能发生变化，而实际情况中，这种变化是经常发生的。因此，我们需要对模型进行适应。<br>对于曲线容量（C）而言，我们可以使用一个随时间变化的动态容量C(t)。<br>而对变化率（k）来说，我们可以假定，变化率是在某些时刻发生突然变化的（这也符合我们上述例子中的实际情况）。我们将这些变化的点用序列\(\boldsymbol{S}=\{s _j\}\)表示，\(\boldsymbol{\delta}=\{\delta _j\}\)表示第\(s _j\)时间点上的变化率增量，令k为基础增长率，令向量\(\boldsymbol{a}(t)=\{0,1\} ^{|S|}\)，有</p>
<script type="math/tex; mode=display">
a _j (t)=\begin{cases}
1,\quad t \geq s _j \\\\
0,\quad other
\end{cases}</script><p>则对增长率，我们有\(k + a _j(t)^T\delta\)，而当增长率发生变化的时候，我们的偏移参数m也需要发生变化，举发生一次变化的图像为例：<br><img src="./time_series1/prophet_growth_curve2.png" alt="avatar"></p>
<p>f曲线是变化前曲线，在s点处，增长率发生变化，变化后曲线为f‘。则我们有：</p>
<script type="math/tex; mode=display">
f(t)=\frac{C}{1+exp(-k(t-m))}</script><script type="math/tex; mode=display">
f(t)=\frac{C}{1+exp(-(k+\delta)(t-(m + \gamma)))}</script><p>其中\(\delta,\gamma\)分别为k和m的增量，又由于曲线在t=s点相交，我们有f(s)=f’(s)。通过整理等式我们可得：</p>
<script type="math/tex; mode=display">
\gamma=\frac{\delta(s-m)}{k+\delta}</script><p>推广到多点的情况，则我们的得到：</p>
<script type="math/tex; mode=display">
\gamma _j=\frac{(s _j -m -\sum _{l<j}\gamma _l)\delta _j}{k+\sum _{l \leq j}\gamma _l}</script><p>令\(\boldsymbol{\gamma}=\{\gamma _j\}\)，则，我们得到最终模型：</p>
<script type="math/tex; mode=display">
g(t)=\frac{C(t)}{1+exp(-(k+\boldsymbol{a}(t)^T\delta)(t-(m+\boldsymbol{a}(t)^t\boldsymbol{\\gamma})))}</script><!--
<p>—&gt;</p>
<blockquote id="fn_PKUTimeSerious">
<sup>PKUTimeSerious</sup>. <a href="http://www.math.pku.edu.cn/teachers/lidf/course/atsa/atsanotes/html/_atsanotes/atsa-estarma.html#estarma-mlearma/, 2016/2018-8.19">应用时间序列分析备课笔记</a><a href="#reffn_PKUTimeSerious" title="Jump back to footnote [PKUTimeSerious] in the text."> &#8617;</a>
</blockquote>
-->
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://liuzhiqi.github.io/blog/2019/09/30/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhiqi Liu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhiqi Liu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/blog/2019/09/30/hello-world/" itemprop="url">Hello World</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-09-30T17:46:05+08:00">
                2019-09-30
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpeg" alt="Zhiqi Liu">
            
              <p class="site-author-name" itemprop="name">Zhiqi Liu</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/liuzhiqi" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yourname@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhiqi Liu</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
